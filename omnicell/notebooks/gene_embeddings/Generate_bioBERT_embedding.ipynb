{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "from omnicell.data.loader import DataLoader, DatasetDetails\n",
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import transformers\n",
    "\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omnicell.data.catalogue import Catalogue, DatasetDetails\n",
    "import numpy as np\n",
    "catalogue = Catalogue(\"./configs/catalogue\")\n",
    "\n",
    "#Getting the dataset details from the data_catalogue.json\n",
    "\n",
    "ds_details = catalogue.get_dataset_details(\"satija_IFNB_raw\")\n",
    "pert_key = ds_details.pert_key\n",
    "control_pert = ds_details.control\n",
    "\n",
    "\n",
    "adata = sc.read(ds_details.path, backed =\"r+\")\n",
    "\n",
    "gene_names = adata.var[\"gene\"]\n",
    "\n",
    "\n",
    "gene_names_idx = gene_names.index.to_numpy().astype(np.int32) - 1\n",
    "\n",
    "gene_names = list(gene_names)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "gene_names_idx\n",
    "\n",
    "tokenizer.pad_token = \"[PAD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "tokenized_batches = []\n",
    "for i in range(0, len(gene_names), batch_size):\n",
    "    indices = gene_names_idx[i:i+batch_size]\n",
    "    genes = gene_names[i:i+batch_size]\n",
    "    tokenized_gene_names_batch = tokenizer(genes, return_tensors=\"pt\", padding=True, truncation=True, max_length=30)\n",
    "    tokenized_gene_names_batch[\"idx\"] = indices\n",
    "    tokenized_batches.append(tokenized_gene_names_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "#Clearing cuda cache and gc to free up memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_representations = torch.zeros((len(gene_names), 768))\n",
    "\n",
    "for batch in tokenized_batches:\n",
    "    # Move batch to GPU\n",
    "    batch_gpu = {k: v.to(\"cuda\") for k, v in batch.items() if k != \"idx\"}\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():  # Prevent gradient computation if not needed\n",
    "        outputs = model(**batch_gpu)\n",
    "    \n",
    "    # Move results back to CPU immediately\n",
    "    mean_logits = torch.mean(outputs.last_hidden_state, dim=1).cpu()\n",
    "    \n",
    "    # Store results\n",
    "    gene_representations[batch[\"idx\"]] = mean_logits\n",
    "    \n",
    "    # Clear GPU cache periodically\n",
    "    if batch[\"idx\"][0] % 100 == 0:  # Every 100 batches\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    # Delete unnecessary tensors\n",
    "    del outputs, batch_gpu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"repr\" : gene_representations, \"gene_names\" : gene_names} , \"notebooks/gene_embeddings/gene_representations_bioBERT.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2309, -0.1624, -0.1522,  ...,  0.3417, -0.0391, -0.2453],\n",
       "        [ 0.0601, -0.1340, -0.0610,  ...,  0.1344, -0.0038, -0.1334],\n",
       "        [ 0.2713, -0.0962, -0.2993,  ..., -0.0051,  0.2950, -0.0486],\n",
       "        ...,\n",
       "        [ 0.1667, -0.2254, -0.1171,  ...,  0.1285,  0.0304, -0.1970],\n",
       "        [ 0.1888, -0.3543, -0.0702,  ...,  0.2456, -0.0742, -0.2947],\n",
       "        [-0.0017, -0.2802, -0.1396,  ..., -0.0196, -0.0011, -0.3765]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_representations.shape\n",
    "\n",
    "gene_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import umap\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert to numpy and standardize\n",
    "data = gene_representations.cpu().numpy()\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# PCA first - reduce to 100 dimensions\n",
    "print(\"Running PCA...\")\n",
    "pca = PCA(n_components=100)\n",
    "data_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Calculate variance explained\n",
    "var_explained = pca.explained_variance_ratio_.cumsum()\n",
    "print(f\"Variance explained by 100 PCs: {var_explained[-1]:.3f}\")\n",
    "\n",
    "# UMAP on PCA results\n",
    "print(\"Running UMAP...\")\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "embedding = reducer.fit_transform(data_pca)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    s=1,\n",
    "    alpha=0.5,\n",
    "    c='blue'\n",
    ")\n",
    "\n",
    "plt.title('UMAP visualization of gene representations (PCA -> UMAP)')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
