{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 10:25:22,658 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/repogle_k562_essential_raw.yaml\n",
      "2025-02-04 10:25:22,660 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNB_raw.yaml\n",
      "2025-02-04 10:25:22,662 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/adamson_INCOMPLETE.yaml\n",
      "2025-02-04 10:25:22,664 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNB_HVG.yaml\n",
      "2025-02-04 10:25:22,665 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/kang.yaml\n",
      "2025-02-04 10:25:22,667 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/essential_gene_knockouts_raw.yaml\n",
      "2025-02-04 10:25:22,669 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNG_raw_INCOMPLETE.yaml\n",
      "2025-02-04 10:25:22,671 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNG_raw.yaml\n",
      "2025-02-04 10:25:22,673 - INFO - Loading training data at path: /orcd/data/omarabu/001/Omnicell_datasets/repogle_k562_essential_raw/K562_essential_raw_singlecell_01.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 10:25:26,621 - INFO - Loaded unpreprocessed data, # of data points: 310385, # of genes: 8563.\n",
      "2025-02-04 10:25:26,621 - INFO - Preprocessing training data\n",
      "2025-02-04 10:25:26,624 - INFO - Using identity features for perturbations\n",
      "2025-02-04 10:25:26,744 - INFO - Removing observations with perturbations not in the dataset as a column\n",
      "2025-02-04 10:25:26,930 - INFO - Removed 189 perturbations that were not in the dataset columns and 0 perturbations that did not have an embedding for a total of 189 perturbations removed out of an initial 2058 perturbations\n",
      "/orcd/data/omarabu/001/njwfish/omnicell/notebooks/../omnicell/data/loader.py:175: ImplicitModificationWarning: Setting element `.obsm['embedding']` of view, initializing view as actual.\n",
      "  adata.obsm[\"embedding\"] = adata.X.toarray().astype('float32')\n",
      "2025-02-04 10:26:04,454 - INFO - Doing OOD split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded:\n",
      "- Number of cells: 279630\n",
      "- Input dimension: 8563\n",
      "- Number of perturbations: 1850\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import yaml\n",
    "import torch\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the path to the directory containing the omnicell package\n",
    "# Assuming the omnicell package is in the parent directory of your notebook\n",
    "sys.path.append('..')  # Adjust this path as needed\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from omnicell.config.config import Config, ETLConfig, ModelConfig, DatasplitConfig, EvalConfig, EmbeddingConfig\n",
    "from omnicell.data.loader import DataLoader\n",
    "from omnicell.constants import PERT_KEY, GENE_EMBEDDING_KEY, CONTROL_PERT\n",
    "from train import get_model\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure paths\n",
    "MODEL_CONFIG = ModelConfig.from_yaml(\"/orcd/data/omarabu/001/njwfish/omnicell/configs/models/scot/proportional_scot.yaml\")\n",
    "ETL_CONFIG = ETLConfig(name = \"no_preprocessing\", log1p = False, drop_unmatched_perts = True)\n",
    "EMBEDDING_CONFIG = EmbeddingConfig(pert_embedding='GenePT')\n",
    "\n",
    "SPLIT_CONFIG = DatasplitConfig.from_yaml(\"/orcd/data/omarabu/001/njwfish/omnicell/configs/splits/repogle_k562_essential_raw/random_splits/rs_accP_k562_ood_ss:ns_20_2_most_pert_0.1/split_0/split_config.yaml\")\n",
    "EVAL_CONFIG = EvalConfig.from_yaml(\"/orcd/data/omarabu/001/njwfish/omnicell/configs/splits/repogle_k562_essential_raw/random_splits/rs_accP_k562_ood_ss:ns_20_2_most_pert_0.1/split_0/eval_config.yaml\")  # Set this if you want to run evaluations\n",
    "\n",
    "# SPLIT_CONFIG = DatasplitConfig.from_yaml(\"/orcd/data/omarabu/001/njwfish/omnicell/configs/splits/satija_IFNB_raw/random_splits/acrossC_ood_ss:10/split_A549/split_config.yaml\")\n",
    "# EVAL_CONFIG = EvalConfig.from_yaml(\"/orcd/data/omarabu/001/njwfish/omnicell/configs/splits/satija_IFNB_raw/random_splits/acrossC_ood_ss:10/split_A549/eval_config.yaml\")  # Set this if you want to run evaluations\n",
    "\n",
    "\n",
    "# Load configurations\n",
    "config = Config(model_config=MODEL_CONFIG,\n",
    "                 etl_config=ETL_CONFIG, \n",
    "                 datasplit_config=SPLIT_CONFIG, \n",
    "                 eval_config=EVAL_CONFIG)\n",
    "\n",
    "\n",
    "#Alternatively you can initialize the config objects manually as follows:\n",
    "# etl_config = ETLConfig(name = XXX, log1p = False, drop_unmatched_perts = False, ...)\n",
    "# model_config = ...\n",
    "# embedding_config = ...\n",
    "# datasplit_config = ...\n",
    "# eval_config = ...\n",
    "# config = Config(etl_config, model_config, datasplit_config, eval_config)\n",
    "\n",
    "\n",
    "config.etl_config.pert_embedding = 'bioBERT'\n",
    "config.etl_config.drop_unmatched_perts = True\n",
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize data loader and load training data\n",
    "loader = DataLoader(config)\n",
    "adata, pert_rep_map = loader.get_training_data()\n",
    "\n",
    "# Get dimensions and perturbation IDs\n",
    "input_dim = adata.obsm['embedding'].shape[1]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pert_ids = adata.obs[PERT_KEY].unique()\n",
    "gene_emb_dim = adata.varm[GENE_EMBEDDING_KEY].shape[1] if GENE_EMBEDDING_KEY in adata.varm else None\n",
    "\n",
    "print(f\"Data loaded:\")\n",
    "print(f\"- Number of cells: {adata.shape[0]}\")\n",
    "print(f\"- Input dimension: {input_dim}\")\n",
    "print(f\"- Number of perturbations: {len(pert_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating source indices\n",
      "Creating target indices\n",
      "Creating pert indices\n",
      "Creating source and target dicts\n",
      "Strata probs [1.85915765e-05 1.85915765e-05 1.85915765e-05 ... 3.62163911e-03\n",
      " 3.68856878e-03 7.42175735e-03]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from omnicell.models.datamodules import get_dataloader\n",
    "dset, dl = get_dataloader(\n",
    "    adata, pert_ids=np.array(adata.obs[PERT_KEY].values), pert_map=pert_rep_map, offline=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted dist calculation took: 0.02s\n",
      "0 / 10691, 0 / 1849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perturbation 9 took: 2.00s\n",
      "0 / 10691, 10 / 1849\n",
      "Perturbation 19 took: 1.83s\n",
      "0 / 10691, 20 / 1849\n",
      "Perturbation 29 took: 1.93s\n",
      "0 / 10691, 30 / 1849\n",
      "Perturbation 39 took: 1.91s\n",
      "0 / 10691, 40 / 1849\n",
      "Perturbation 49 took: 1.87s\n",
      "0 / 10691, 50 / 1849\n",
      "Perturbation 59 took: 1.97s\n",
      "0 / 10691, 60 / 1849\n",
      "Perturbation 69 took: 1.96s\n",
      "0 / 10691, 70 / 1849\n",
      "Perturbation 79 took: 1.92s\n",
      "0 / 10691, 80 / 1849\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "from omnicell.models.distribute_shift import (\n",
    "    sample_pert, \n",
    "    get_proportional_weighted_dist\n",
    ")\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "# Add overall timing\n",
    "total_start_time = time.time()\n",
    "\n",
    "for stratum in dset.strata:\n",
    "\n",
    "    iteration_start_time = time.time()\n",
    "    source_batch = {} \n",
    "    synthetic_counterfactual_batch = {}\n",
    "\n",
    "    num_ctrls = dset.source[stratum].shape[0]\n",
    "\n",
    "    for i in range(0, num_ctrls, batch_size):   \n",
    "        source_batch[stratum] = X_ctrl = dset.source[stratum][i:i+batch_size]\n",
    "        synthetic_counterfactual_batch[stratum] = {}\n",
    "\n",
    "        mean_ctrl = X_ctrl.mean(axis=0)\n",
    "        \n",
    "        # Time the weighted dist calculation\n",
    "        dist_start = time.time()\n",
    "        weighted_dist = get_proportional_weighted_dist(X_ctrl)\n",
    "        \n",
    "        dist_time = time.time() - dist_start\n",
    "        print(f\"Weighted dist calculation took: {dist_time:.2f}s\")\n",
    "\n",
    "        for j, pert in enumerate(dset.unique_pert_ids):\n",
    "            if j % 10 == 0:\n",
    "                pert_start = time.time()\n",
    "                print(f\"{i} / {num_ctrls}, {j} / {len(dset.unique_pert_ids)}\")\n",
    "            \n",
    "            X_pert = dset.target[stratum][pert]\n",
    "            mean_pert = X_pert.mean(axis=0)\n",
    "            mean_shift = mean_pert - mean_ctrl\n",
    "            \n",
    "            # Time the sample_pert call\n",
    "            preds = sample_pert(\n",
    "                X_ctrl, \n",
    "                weighted_dist, \n",
    "                mean_shift, \n",
    "                max_rejections=100, \n",
    "                num_threads=2\n",
    "            )\n",
    "            \n",
    "            synthetic_counterfactual_batch[stratum][pert] = preds.astype(np.int16)\n",
    "            \n",
    "            if (j + 1) % 10 == 0:\n",
    "                pert_time = time.time() - pert_start\n",
    "                print(f\"Perturbation {j} took: {pert_time:.2f}s\")\n",
    "        \n",
    "    # Save timing data along with results\n",
    "    data_dict = {\n",
    "        'synthetic_counterfactuals': synthetic_counterfactual_batch,\n",
    "        'source': source_batch,\n",
    "        'unique_pert_ids': dset.unique_pert_ids,\n",
    "        'strata': dset.strata,\n",
    "    }\n",
    "    break\n",
    "\n",
    "    # with open(f'/orcd/data/omarabu/001/Omnicell_datasets/repogle_k562_essential_raw/proportional_scot/synthetic_counterfactuals_{i}.pkl', 'wb') as f:\n",
    "    #     pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnicell",
   "language": "python",
   "name": "omnicell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
