{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 12:24:41,360 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/repogle_k562_essential_raw.yaml\n",
      "2025-02-02 12:24:41,362 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNB_raw.yaml\n",
      "2025-02-02 12:24:41,363 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/adamson_INCOMPLETE.yaml\n",
      "2025-02-02 12:24:41,365 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNB_HVG.yaml\n",
      "2025-02-02 12:24:41,366 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/kang.yaml\n",
      "2025-02-02 12:24:41,367 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/essential_gene_knockouts_raw.yaml\n",
      "2025-02-02 12:24:41,368 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNG_raw_INCOMPLETE.yaml\n",
      "2025-02-02 12:24:41,369 - INFO - Loading data catalogue from /orcd/data/omarabu/001/njwfish/omnicell/configs/catalogue/satija_IFNG_raw.yaml\n",
      "2025-02-02 12:24:41,370 - INFO - Loading training data at path: /orcd/data/omarabu/001/Omnicell_datasets/repogle_k562_essential_raw/K562_essential_raw_singlecell_01.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 12:24:44,787 - INFO - Loaded unpreprocessed data, # of data points: 310385, # of genes: 8563.\n",
      "2025-02-02 12:24:44,788 - INFO - Preprocessing training data\n",
      "2025-02-02 12:24:44,789 - INFO - Using identity features for perturbations\n",
      "2025-02-02 12:24:44,911 - INFO - Removing observations with perturbations not in the dataset as a column\n",
      "2025-02-02 12:24:45,109 - INFO - Removed 189 perturbations that were not in the dataset columns and 0 perturbations that did not have an embedding for a total of 189 perturbations removed out of an initial 2058 perturbations\n",
      "/orcd/data/omarabu/001/njwfish/omnicell/notebooks/../omnicell/data/loader.py:178: ImplicitModificationWarning: Setting element `.obsm['embedding']` of view, initializing view as actual.\n",
      "  adata.obsm[\"embedding\"] = adata.X.toarray().astype('float32')\n",
      "2025-02-02 12:25:22,401 - INFO - Doing OOD split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded:\n",
      "- Number of cells: 279630\n",
      "- Input dimension: 8563\n",
      "- Number of perturbations: 1850\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import yaml\n",
    "import torch\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the path to the directory containing the omnicell package\n",
    "# Assuming the omnicell package is in the parent directory of your notebook\n",
    "sys.path.append('..')  # Adjust this path as ne\n",
    "import yaml\n",
    "import torch\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from omnicell.config.config import Config, ETLConfig, ModelConfig, DatasplitConfig, EvalConfig, EmbeddingConfig\n",
    "from omnicell.data.loader import DataLoader\n",
    "from omnicell.constants import PERT_KEY, GENE_EMBEDDING_KEY, CONTROL_PERT\n",
    "from train import get_model\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure paths\n",
    "MODEL_CONFIG = ModelConfig.from_yaml(\"/orcd/data/omarabu/001/njwfish/omnicell/configs/models/scot/proportional_scot.yaml\")\n",
    "ETL_CONFIG = ETLConfig(name = \"no_preprocessing\", log1p = False, drop_unmatched_perts = True)\n",
    "EMBEDDING_CONFIG = EmbeddingConfig(pert_embedding='GenePT')\n",
    "\n",
    "SPLIT_CONFIG = DatasplitConfig.from_yaml(\"/orcd/data/omarabu/001/njwfish/omnicell/configs/splits/repogle_k562_essential_raw/random_splits/rs_accP_k562_ood_ss:ns_20_2_most_pert_0.1/split_0/split_config.yaml\")\n",
    "EVAL_CONFIG = EvalConfig.from_yaml(\"/orcd/data/omarabu/001/njwfish/omnicell/configs/splits/repogle_k562_essential_raw/random_splits/rs_accP_k562_ood_ss:ns_20_2_most_pert_0.1/split_0/eval_config.yaml\")  # Set this if you want to run evaluations\n",
    "\n",
    "# SPLIT_CONFIG = DatasplitConfig.from_yaml(\"/orcd/data/omarabu/001/njwfish/omnicell/configs/splits/satija_IFNB_raw/random_splits/acrossC_ood_ss:10/split_A549/split_config.yaml\")\n",
    "# EVAL_CONFIG = EvalConfig.from_yaml(\"/orcd/data/omarabu/001/njwfish/omnicell/configs/splits/satija_IFNB_raw/random_splits/acrossC_ood_ss:10/split_A549/eval_config.yaml\")  # Set this if you want to run evaluations\n",
    "\n",
    "# Load configurations\n",
    "config = Config(model_config=MODEL_CONFIG,\n",
    "                 etl_config=ETL_CONFIG, \n",
    "                 datasplit_config=SPLIT_CONFIG, \n",
    "                 eval_config=EVAL_CONFIG)\n",
    "\n",
    "\n",
    "#Alternatively you can initialize the config objects manually as follows:\n",
    "# etl_config = ETLConfig(name = XXX, log1p = False, drop_unmatched_perts = False, ...)\n",
    "# model_config = ...\n",
    "# embedding_config = ...\n",
    "# datasplit_config = ...\n",
    "# eval_config = ...\n",
    "# config = Config(etl_config, model_config, datasplit_config, eval_config)\n",
    "\n",
    "\n",
    "config.etl_config.pert_embedding = 'bioBERT'\n",
    "config.etl_config.drop_unmatched_perts = True\n",
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize data loader and load training data\n",
    "loader = DataLoader(config)\n",
    "adata, pert_rep_map = loader.get_training_data()\n",
    "\n",
    "# Get dimensions and perturbation IDs\n",
    "input_dim = adata.obsm['embedding'].shape[1]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pert_ids = adata.obs[PERT_KEY].unique()\n",
    "gene_emb_dim = adata.varm[GENE_EMBEDDING_KEY].shape[1] if GENE_EMBEDDING_KEY in adata.varm else None\n",
    "\n",
    "print(f\"Data loaded:\")\n",
    "print(f\"- Number of cells: {adata.shape[0]}\")\n",
    "print(f\"- Input dimension: {input_dim}\")\n",
    "print(f\"- Number of perturbations: {len(pert_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k562', 'k562', 'k562', 'k562', 'k562', ..., 'k562', 'k562', 'k562', 'k562', 'k562']\n",
      "Length: 10691\n",
      "Categories (1, object): ['k562'] ['k562'] 1\n",
      "Creating source indices\n",
      "Creating target indices\n",
      "Creating pert indices\n",
      "Creating source and target dicts\n",
      "Strata probs [1.85915765e-05 1.85915765e-05 1.85915765e-05 ... 3.62163911e-03\n",
      " 3.68856878e-03 7.42175735e-03]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from omnicell.models.datamodules import get_dataloader\n",
    "dset, ns, dl = get_dataloader(adata, pert_ids=np.array(adata.obs[PERT_KEY].values), pert_map=pert_rep_map, collate='ot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perturbation 0 took: 5.06s\n",
      "Perturbation 1 took: 5.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orcd/data/omarabu/001/njwfish/omnicell/notebooks/../omnicell/models/distribute_shift_numpy.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  p = p / p.sum()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pvals < 0, pvals > 1 or pvals contains NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m mean_pert \u001b[38;5;241m=\u001b[39m X_pert\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     16\u001b[0m mean_shift \u001b[38;5;241m=\u001b[39m mean_pert \u001b[38;5;241m-\u001b[39m mean_ctrl\n\u001b[0;32m---> 18\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43msample_pert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_ctrl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweighted_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_shift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rejections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     20\u001b[0m     pert_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m pert_start\n",
      "File \u001b[0;32m/orcd/data/omarabu/001/njwfish/omnicell/notebooks/../omnicell/models/distribute_shift_numpy.py:51\u001b[0m, in \u001b[0;36msample_pert\u001b[0;34m(ctrl, weighted_dist, mean_shift, max_rejections)\u001b[0m\n\u001b[1;32m     49\u001b[0m max_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m*\u001b[39m ctrl\n\u001b[1;32m     50\u001b[0m max_count[:, count_shift \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m---> 51\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43msample_multinomial_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweighted_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount_shift\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rejections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rejections\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m sampled_pert \u001b[38;5;241m=\u001b[39m ctrl \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msign(count_shift) \u001b[38;5;241m*\u001b[39m samples\n\u001b[1;32m     55\u001b[0m sampled_pert \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(sampled_pert, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/orcd/data/omarabu/001/njwfish/omnicell/notebooks/../omnicell/models/distribute_shift_numpy.py:38\u001b[0m, in \u001b[0;36msample_multinomial_batch\u001b[0;34m(probs, counts, max_count, max_rejections)\u001b[0m\n\u001b[1;32m     36\u001b[0m s[over_max] \u001b[38;5;241m=\u001b[39m mc[over_max]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# assert np.sum(s) + n_resample == c\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_resample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m over_max \u001b[38;5;241m=\u001b[39m s \u001b[38;5;241m>\u001b[39m mc\n\u001b[1;32m     40\u001b[0m num_rejections \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:4386\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.multinomial\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:396\u001b[0m, in \u001b[0;36mnumpy.random._common.check_array_constraint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:382\u001b[0m, in \u001b[0;36mnumpy.random._common._check_array_cons_bounded_0_1\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: pvals < 0, pvals > 1 or pvals contains NaNs"
     ]
    }
   ],
   "source": [
    "from omnicell.models.distribute_shift_numpy import sample_pert, get_proportional_weighted_dist\n",
    "\n",
    "synthetic_counterfactuals = {}\n",
    "for stratum in dset.strata:\n",
    "    synthetic_counterfactuals[stratum] = {}\n",
    "    X_ctrl = dset.source[stratum]\n",
    "    mean_ctrl = X_ctrl.mean(axis=0)\n",
    "    weighted_dist = get_proportional_weighted_dist(X_ctrl)\n",
    "    for i, pert in enumerate(dset.unique_pert_ids):\n",
    "        if i % 1 == 0:\n",
    "            pert_start = time.time()\n",
    "            # print(f\"{i} / {len(dset.unique_pert_ids)}\")\n",
    "        \n",
    "        X_pert = dset.target[stratum][pert]\n",
    "        mean_pert = X_pert.mean(axis=0)\n",
    "        mean_shift = mean_pert - mean_ctrl\n",
    "\n",
    "        preds = sample_pert(X_ctrl, weighted_dist, mean_shift, max_rejections=100)\n",
    "        if i % 1 == 0:\n",
    "            pert_time = time.time() - pert_start\n",
    "            print(f\"Perturbation {i} took: {pert_time:.2f}s\")\n",
    "        synthetic_counterfactuals[stratum][pert] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted dist calculation took: 0.06s\n",
      "0 / 10691, 0 / 1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orcd/data/omarabu/001/njwfish/omnicell/notebooks/../omnicell/models/distribute_shift_numpy.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  p = p / p.sum()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pvals < 0, pvals > 1 or pvals contains NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m mean_shift \u001b[38;5;241m=\u001b[39m mean_pert \u001b[38;5;241m-\u001b[39m mean_ctrl\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Time the sample_pert call\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43msample_pert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_ctrl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweighted_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmean_shift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_rejections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# num_threads=2\u001b[39;49;00m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m synthetic_counterfactual_batch[stratum][pert] \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint16)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/orcd/data/omarabu/001/njwfish/omnicell/notebooks/../omnicell/models/distribute_shift_numpy.py:51\u001b[0m, in \u001b[0;36msample_pert\u001b[0;34m(ctrl, weighted_dist, mean_shift, max_rejections)\u001b[0m\n\u001b[1;32m     49\u001b[0m max_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m*\u001b[39m ctrl\n\u001b[1;32m     50\u001b[0m max_count[:, count_shift \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m---> 51\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43msample_multinomial_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweighted_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount_shift\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rejections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rejections\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m sampled_pert \u001b[38;5;241m=\u001b[39m ctrl \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msign(count_shift) \u001b[38;5;241m*\u001b[39m samples\n\u001b[1;32m     55\u001b[0m sampled_pert \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(sampled_pert, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/orcd/data/omarabu/001/njwfish/omnicell/notebooks/../omnicell/models/distribute_shift_numpy.py:38\u001b[0m, in \u001b[0;36msample_multinomial_batch\u001b[0;34m(probs, counts, max_count, max_rejections)\u001b[0m\n\u001b[1;32m     36\u001b[0m s[over_max] \u001b[38;5;241m=\u001b[39m mc[over_max]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# assert np.sum(s) + n_resample == c\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_resample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m over_max \u001b[38;5;241m=\u001b[39m s \u001b[38;5;241m>\u001b[39m mc\n\u001b[1;32m     40\u001b[0m num_rejections \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:4386\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.multinomial\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:396\u001b[0m, in \u001b[0;36mnumpy.random._common.check_array_constraint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:382\u001b[0m, in \u001b[0;36mnumpy.random._common._check_array_cons_bounded_0_1\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: pvals < 0, pvals > 1 or pvals contains NaNs"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "from omnicell.models.distribute_shift_numpy import (\n",
    "    sample_pert, \n",
    "    get_proportional_weighted_dist\n",
    ")\n",
    "\n",
    "num_ctrls = dset.source['k562'].shape[0]\n",
    "batch_size = 512\n",
    "\n",
    "# Add overall timing\n",
    "total_start_time = time.time()\n",
    "\n",
    "for i in range(0, num_ctrls, batch_size):   \n",
    "    iteration_start_time = time.time()\n",
    "    source_batch = {} \n",
    "    synthetic_counterfactual_batch = {}\n",
    "    \n",
    "    for stratum in dset.strata:\n",
    "        source_batch[stratum] = X_ctrl = dset.source[stratum][i:i+batch_size]\n",
    "        synthetic_counterfactual_batch[stratum] = {}\n",
    "\n",
    "        mean_ctrl = X_ctrl.mean(axis=0)\n",
    "        \n",
    "        # Time the weighted dist calculation\n",
    "        dist_start = time.time()\n",
    "        weighted_dist = get_proportional_weighted_dist(X_ctrl)\n",
    "        weighted_dist = weighted_dist.astype(np.float64)\n",
    "        s = weighted_dist.sum(axis=0)\n",
    "        weighted_dist[:, s > 0] /= s[s > 0]\n",
    "        \n",
    "        dist_time = time.time() - dist_start\n",
    "        print(f\"Weighted dist calculation took: {dist_time:.2f}s\")\n",
    "\n",
    "        for j, pert in enumerate(dset.unique_pert_ids):\n",
    "            if j % 10 == 0:\n",
    "                pert_start = time.time()\n",
    "                print(f\"{i} / {num_ctrls}, {j} / {len(dset.unique_pert_ids)}\")\n",
    "            \n",
    "            X_pert = dset.target[stratum][pert]\n",
    "            mean_pert = X_pert.mean(axis=0)\n",
    "            mean_shift = mean_pert - mean_ctrl\n",
    "            \n",
    "            # Time the sample_pert call\n",
    "            preds = sample_pert(\n",
    "                X_ctrl, \n",
    "                weighted_dist, \n",
    "                mean_shift, \n",
    "                max_rejections=100, \n",
    "                # num_threads=2\n",
    "            )\n",
    "            \n",
    "            synthetic_counterfactual_batch[stratum][pert] = preds.astype(np.int16)\n",
    "            \n",
    "            if (j + 1) % 10 == 0:\n",
    "                pert_time = time.time() - pert_start\n",
    "                print(f\"Perturbation {j} took: {pert_time:.2f}s\")\n",
    "        \n",
    "    # Save timing data along with results\n",
    "    data_dict = {\n",
    "        'synthetic_counterfactuals': synthetic_counterfactual_batch,\n",
    "        'source': source_batch,\n",
    "        'unique_pert_ids': dset.unique_pert_ids,\n",
    "        'strata': dset.strata,\n",
    "    }\n",
    "\n",
    "    with open(f'/orcd/data/omarabu/001/Omnicell_datasets/repogle_k562_essential_raw/proportional_scot/synthetic_counterfactuals_{i}.pkl', 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted dist calculation took: 0.02s\n",
      "0 / 10691, 0 / 1849\n",
      "Perturbation 0 took: 0.18s (sampling: 0.17s)\n",
      "0 / 10691, 1 / 1849\n",
      "Perturbation 1 took: 0.16s (sampling: 0.16s)\n",
      "0 / 10691, 2 / 1849\n",
      "Perturbation 2 took: 0.25s (sampling: 0.25s)\n",
      "0 / 10691, 3 / 1849\n",
      "Perturbation 3 took: 0.18s (sampling: 0.18s)\n",
      "0 / 10691, 4 / 1849\n",
      "Perturbation 4 took: 0.18s (sampling: 0.18s)\n",
      "0 / 10691, 5 / 1849\n",
      "Perturbation 5 took: 0.16s (sampling: 0.16s)\n",
      "0 / 10691, 6 / 1849\n",
      "Perturbation 6 took: 0.17s (sampling: 0.17s)\n",
      "0 / 10691, 7 / 1849\n",
      "Perturbation 7 took: 0.16s (sampling: 0.15s)\n",
      "0 / 10691, 8 / 1849\n",
      "Perturbation 8 took: 0.18s (sampling: 0.18s)\n",
      "0 / 10691, 9 / 1849\n",
      "Perturbation 9 took: 0.17s (sampling: 0.16s)\n",
      "0 / 10691, 10 / 1849\n",
      "Perturbation 10 took: 0.20s (sampling: 0.20s)\n",
      "0 / 10691, 11 / 1849\n",
      "Perturbation 11 took: 0.18s (sampling: 0.17s)\n",
      "0 / 10691, 12 / 1849\n",
      "Perturbation 12 took: 0.18s (sampling: 0.18s)\n",
      "0 / 10691, 13 / 1849\n",
      "Perturbation 13 took: 0.17s (sampling: 0.16s)\n",
      "0 / 10691, 14 / 1849\n",
      "Perturbation 14 took: 0.16s (sampling: 0.16s)\n",
      "0 / 10691, 15 / 1849\n",
      "Perturbation 15 took: 0.16s (sampling: 0.16s)\n",
      "0 / 10691, 16 / 1849\n",
      "Perturbation 16 took: 0.18s (sampling: 0.18s)\n",
      "0 / 10691, 17 / 1849\n",
      "Perturbation 17 took: 0.16s (sampling: 0.15s)\n",
      "0 / 10691, 18 / 1849\n",
      "Perturbation 18 took: 0.17s (sampling: 0.17s)\n",
      "0 / 10691, 19 / 1849\n",
      "Perturbation 19 took: 0.15s (sampling: 0.15s)\n",
      "0 / 10691, 20 / 1849\n",
      "Perturbation 20 took: 0.18s (sampling: 0.18s)\n",
      "0 / 10691, 21 / 1849\n",
      "Perturbation 21 took: 0.16s (sampling: 0.16s)\n",
      "0 / 10691, 22 / 1849\n",
      "Perturbation 22 took: 0.19s (sampling: 0.18s)\n",
      "0 / 10691, 23 / 1849\n",
      "Perturbation 23 took: 0.20s (sampling: 0.20s)\n",
      "0 / 10691, 24 / 1849\n",
      "Perturbation 24 took: 0.18s (sampling: 0.18s)\n",
      "0 / 10691, 25 / 1849\n",
      "Perturbation 25 took: 0.17s (sampling: 0.17s)\n",
      "0 / 10691, 26 / 1849\n",
      "Perturbation 26 took: 0.18s (sampling: 0.18s)\n",
      "0 / 10691, 27 / 1849\n",
      "Perturbation 27 took: 0.20s (sampling: 0.20s)\n",
      "0 / 10691, 28 / 1849\n",
      "Perturbation 28 took: 0.18s (sampling: 0.17s)\n",
      "0 / 10691, 29 / 1849\n",
      "Perturbation 29 took: 0.16s (sampling: 0.16s)\n",
      "0 / 10691, 30 / 1849\n",
      "Perturbation 30 took: 0.17s (sampling: 0.17s)\n",
      "0 / 10691, 31 / 1849\n",
      "Perturbation 31 took: 0.21s (sampling: 0.20s)\n",
      "0 / 10691, 32 / 1849\n",
      "Perturbation 32 took: 0.23s (sampling: 0.23s)\n",
      "0 / 10691, 33 / 1849\n",
      "Perturbation 33 took: 0.17s (sampling: 0.17s)\n",
      "0 / 10691, 34 / 1849\n",
      "Perturbation 34 took: 0.18s (sampling: 0.18s)\n",
      "0 / 10691, 35 / 1849\n",
      "Perturbation 35 took: 0.18s (sampling: 0.18s)\n",
      "0 / 10691, 36 / 1849\n",
      "Perturbation 36 took: 0.16s (sampling: 0.16s)\n",
      "0 / 10691, 37 / 1849\n",
      "Perturbation 37 took: 0.17s (sampling: 0.17s)\n",
      "0 / 10691, 38 / 1849\n",
      "Perturbation 38 took: 0.16s (sampling: 0.16s)\n",
      "0 / 10691, 39 / 1849\n",
      "Perturbation 39 took: 0.16s (sampling: 0.16s)\n",
      "0 / 10691, 40 / 1849\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m num_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     46\u001b[0m min_block_size \u001b[38;5;241m=\u001b[39m X_ctrl\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_threads \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 47\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43msample_pert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_ctrl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweighted_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_shift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_rejections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_block_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_block_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m sample_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m sample_start\n\u001b[1;32m     51\u001b[0m synthetic_counterfactual_batch[stratum][pert] \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint16)\n",
      "File \u001b[0;32mdistribute_shift.pyx:211\u001b[0m, in \u001b[0;36mdistribute_shift.sample_pert\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mdistribute_shift.pyx:84\u001b[0m, in \u001b[0;36mdistribute_shift.sample_multinomial_batch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mdistribute_shift.pyx:172\u001b[0m, in \u001b[0;36mdistribute_shift._process_column_block\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/omnicell/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:2250\u001b[0m, in \u001b[0;36m_sum_dispatcher\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2180\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2181\u001b[0m \u001b[38;5;124;03m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[1;32m   2182\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2245\u001b[0m \n\u001b[1;32m   2246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m, a_min, a_max, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 2250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2251\u001b[0m                     initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[1;32m   2255\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[1;32m   2256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2257\u001b[0m         initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "from omnicell.models.distribute_shift import (\n",
    "    get_proportional_weighted_dist,\n",
    "    sample_multinomial_batch,\n",
    "    sample_pert\n",
    ")\n",
    "\n",
    "batch_size = 512\n",
    "num_ctrls = dset.source['k562'].shape[0]\n",
    "\n",
    "# Add overall timing\n",
    "total_start_time = time.time()\n",
    "iteration_times = []\n",
    "pert_times = []\n",
    "\n",
    "for i in range(0, num_ctrls, batch_size):\n",
    "    iteration_start_time = time.time()\n",
    "    source_batch = {} \n",
    "    synthetic_counterfactual_batch = {}\n",
    "    \n",
    "    for stratum in dset.strata:\n",
    "        source_batch[stratum] = X_ctrl = dset.source[stratum][i:i+512]\n",
    "        synthetic_counterfactual_batch[stratum] = {}\n",
    "\n",
    "        mean_ctrl = X_ctrl.mean(axis=0)\n",
    "        \n",
    "        # Time the weighted dist calculation\n",
    "        dist_start = time.time()\n",
    "        weighted_dist = get_proportional_weighted_dist(X_ctrl)\n",
    "        dist_time = time.time() - dist_start\n",
    "        print(f\"Weighted dist calculation took: {dist_time:.2f}s\")\n",
    "\n",
    "        for j, pert in enumerate(dset.unique_pert_ids):\n",
    "            pert_start = time.time()\n",
    "            \n",
    "            print(f\"{i} / {num_ctrls}, {j} / {len(dset.unique_pert_ids)}\")\n",
    "            \n",
    "            X_pert = dset.target[stratum][pert]\n",
    "            mean_pert = X_pert.mean(axis=0)\n",
    "            mean_shift = mean_pert - mean_ctrl\n",
    "            \n",
    "            # Time the sample_pert call\n",
    "            sample_start = time.time()\n",
    "            num_threads = 2\n",
    "            min_block_size = X_ctrl.shape[1] // num_threads + 1\n",
    "            preds = sample_pert(X_ctrl, weighted_dist, mean_shift, \n",
    "                              max_rejections=100, min_block_size=min_block_size, num_threads=num_threads)\n",
    "            sample_time = time.time() - sample_start\n",
    "            \n",
    "            synthetic_counterfactual_batch[stratum][pert] = preds.astype(np.int16)\n",
    "            \n",
    "            pert_time = time.time() - pert_start\n",
    "            pert_times.append({\n",
    "                'iteration': i,\n",
    "                'pert_idx': j,\n",
    "                'total_time': pert_time,\n",
    "                'sample_time': sample_time\n",
    "            })\n",
    "            \n",
    "            print(f\"Perturbation {j} took: {pert_time:.2f}s (sampling: {sample_time:.2f}s)\")\n",
    "        \n",
    "    # Save timing data along with results\n",
    "    data_dict = {\n",
    "        'synthetic_counterfactuals': synthetic_counterfactual_batch,\n",
    "        'source': source_batch,\n",
    "        'unique_pert_ids': dset.unique_pert_ids,\n",
    "        'strata': dset.strata,\n",
    "        'timing': {\n",
    "            'pert_times': pert_times,\n",
    "            'iteration_time': time.time() - iteration_start_time\n",
    "        }\n",
    "    }\n",
    "\n",
    "    iteration_times.append(time.time() - iteration_start_time)\n",
    "    print(f\"\\nIteration {i} took: {iteration_times[-1]:.2f}s\")\n",
    "    print(f\"Average perturbation time: {np.mean([p['total_time'] for p in pert_times[-len(dset.unique_pert_ids):]]):.2f}s\")\n",
    "    print(f\"Average sampling time: {np.mean([p['sample_time'] for p in pert_times[-len(dset.unique_pert_ids):]]):.2f}s\")\n",
    "\n",
    "    with open(f'/orcd/data/omarabu/001/Omnicell_datasets/repogle_k562_essential_raw/proportional_scot/synthetic_counterfactuals_{i}.pkl', 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted dist calculation took: 0.02s\n",
      "0 / 10691, 0 / 1849\n",
      "Perturbation 0 took: 0.29s (sampling: 0.29s)\n",
      "0 / 10691, 1 / 1849\n",
      "Perturbation 1 took: 0.29s (sampling: 0.29s)\n",
      "0 / 10691, 2 / 1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orcd/data/omarabu/001/njwfish/omnicell/notebooks/../omnicell/models/distribute_shift_numpy.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  p = p / p.sum()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pvals < 0, pvals > 1 or pvals contains NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Time the sample_pert call\u001b[39;00m\n\u001b[1;32m     44\u001b[0m sample_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 45\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43msample_pert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_ctrl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweighted_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_shift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_rejections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m sample_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m sample_start\n\u001b[1;32m     49\u001b[0m synthetic_counterfactual_batch[stratum][pert] \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint16)\n",
      "File \u001b[0;32m/orcd/data/omarabu/001/njwfish/omnicell/notebooks/../omnicell/models/distribute_shift_numpy.py:51\u001b[0m, in \u001b[0;36msample_pert\u001b[0;34m(ctrl, weighted_dist, mean_shift, max_rejections)\u001b[0m\n\u001b[1;32m     49\u001b[0m max_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m*\u001b[39m ctrl\n\u001b[1;32m     50\u001b[0m max_count[:, count_shift \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m---> 51\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43msample_multinomial_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweighted_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount_shift\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rejections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rejections\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m sampled_pert \u001b[38;5;241m=\u001b[39m ctrl \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msign(count_shift) \u001b[38;5;241m*\u001b[39m samples\n\u001b[1;32m     55\u001b[0m sampled_pert \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(sampled_pert, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/orcd/data/omarabu/001/njwfish/omnicell/notebooks/../omnicell/models/distribute_shift_numpy.py:38\u001b[0m, in \u001b[0;36msample_multinomial_batch\u001b[0;34m(probs, counts, max_count, max_rejections)\u001b[0m\n\u001b[1;32m     36\u001b[0m s[over_max] \u001b[38;5;241m=\u001b[39m mc[over_max]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# assert np.sum(s) + n_resample == c\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_resample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m over_max \u001b[38;5;241m=\u001b[39m s \u001b[38;5;241m>\u001b[39m mc\n\u001b[1;32m     40\u001b[0m num_rejections \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:4386\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.multinomial\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:396\u001b[0m, in \u001b[0;36mnumpy.random._common.check_array_constraint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:382\u001b[0m, in \u001b[0;36mnumpy.random._common._check_array_cons_bounded_0_1\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: pvals < 0, pvals > 1 or pvals contains NaNs"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "from omnicell.models.distribute_shift_numpy import (\n",
    "    get_proportional_weighted_dist,\n",
    "    sample_multinomial_batch,\n",
    "    sample_pert\n",
    ")\n",
    "\n",
    "batch_size = 512\n",
    "num_ctrls = dset.source['k562'].shape[0]\n",
    "\n",
    "# Add overall timing\n",
    "total_start_time = time.time()\n",
    "iteration_times = []\n",
    "pert_times = []\n",
    "\n",
    "for i in range(0, num_ctrls, batch_size):\n",
    "    iteration_start_time = time.time()\n",
    "    source_batch = {} \n",
    "    synthetic_counterfactual_batch = {}\n",
    "    \n",
    "    for stratum in dset.strata:\n",
    "        source_batch[stratum] = X_ctrl = dset.source[stratum][i:i+512]\n",
    "        synthetic_counterfactual_batch[stratum] = {}\n",
    "\n",
    "        mean_ctrl = X_ctrl.mean(axis=0)\n",
    "        \n",
    "        # Time the weighted dist calculation\n",
    "        dist_start = time.time()\n",
    "        weighted_dist = get_proportional_weighted_dist(X_ctrl)\n",
    "        dist_time = time.time() - dist_start\n",
    "        print(f\"Weighted dist calculation took: {dist_time:.2f}s\")\n",
    "\n",
    "        for j, pert in enumerate(dset.unique_pert_ids):\n",
    "            pert_start = time.time()\n",
    "            \n",
    "            print(f\"{i} / {num_ctrls}, {j} / {len(dset.unique_pert_ids)}\")\n",
    "            \n",
    "            X_pert = dset.target[stratum][pert]\n",
    "            mean_pert = X_pert.mean(axis=0)\n",
    "            mean_shift = mean_pert - mean_ctrl\n",
    "            \n",
    "            # Time the sample_pert call\n",
    "            sample_start = time.time()\n",
    "            preds = sample_pert(X_ctrl, weighted_dist, mean_shift, \n",
    "                              max_rejections=100)\n",
    "            sample_time = time.time() - sample_start\n",
    "            \n",
    "            synthetic_counterfactual_batch[stratum][pert] = preds.astype(np.int16)\n",
    "            \n",
    "            pert_time = time.time() - pert_start\n",
    "            pert_times.append({\n",
    "                'iteration': i,\n",
    "                'pert_idx': j,\n",
    "                'total_time': pert_time,\n",
    "                'sample_time': sample_time\n",
    "            })\n",
    "            \n",
    "            print(f\"Perturbation {j} took: {pert_time:.2f}s (sampling: {sample_time:.2f}s)\")\n",
    "        \n",
    "    # Save timing data along with results\n",
    "    data_dict = {\n",
    "        'synthetic_counterfactuals': synthetic_counterfactual_batch,\n",
    "        'source': source_batch,\n",
    "        'unique_pert_ids': dset.unique_pert_ids,\n",
    "        'strata': dset.strata,\n",
    "        'timing': {\n",
    "            'pert_times': pert_times,\n",
    "            'iteration_time': time.time() - iteration_start_time\n",
    "        }\n",
    "    }\n",
    "\n",
    "    iteration_times.append(time.time() - iteration_start_time)\n",
    "    print(f\"\\nIteration {i} took: {iteration_times[-1]:.2f}s\")\n",
    "    print(f\"Average perturbation time: {np.mean([p['total_time'] for p in pert_times[-len(dset.unique_pert_ids):]]):.2f}s\")\n",
    "    print(f\"Average sampling time: {np.mean([p['sample_time'] for p in pert_times[-len(dset.unique_pert_ids):]]):.2f}s\")\n",
    "\n",
    "    with open(f'/orcd/data/omarabu/001/Omnicell_datasets/repogle_k562_essential_raw/proportional_scot/synthetic_counterfactuals_{i}.pkl', 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from omnicell.models.distribute_shift import sample_pert, get_proportional_weighted_dist\n",
    "\n",
    "batch_size = 512\n",
    "num_batches = dset.source['k562'].shape[0] // batch_size\n",
    "\n",
    "for i in range(0, dset.source['k562'].shape[0], batch_size):\n",
    "    source_batch = {} \n",
    "    synthetic_counterfactual_batch = {}\n",
    "    for stratum in dset.strata:\n",
    "        source_batch[stratum] = dset.source[stratum][i:i+512]\n",
    "        synthetic_counterfactual_batch[stratum] = {}\n",
    "\n",
    "        for j, pert in enumerate(dset.unique_pert_ids):\n",
    "            \n",
    "            print(f\"{i} / {num_batches}, {j} / {len(dset.unique_pert_ids)}\")\n",
    "            X_ctrl = source_batch[stratum]\n",
    "            X_pert = dset.target[stratum][pert]\n",
    "            mean_ctrl = X_ctrl.mean(axis=0)\n",
    "            mean_pert = X_pert.mean(axis=0)\n",
    "            \n",
    "            mean_shift = mean_pert - mean_ctrl\n",
    "            logger.debug(f\"Mean shift shape: {mean_shift.shape}\")\n",
    "\n",
    "            weighted_dist = get_proportional_weighted_dist(X_ctrl)\n",
    "            \n",
    "            preds = sample_pert(X_ctrl, weighted_dist, mean_shift, max_rejections=100)\n",
    "            synthetic_counterfactual_batch[stratum][pert] = preds.astype(np.int16)\n",
    "        \n",
    "    # Save as before\n",
    "    data_dict = {\n",
    "        'synthetic_counterfactuals': synthetic_counterfactual_batch,\n",
    "        'source': source_batch,\n",
    "        'unique_pert_ids': dset.unique_pert_ids,\n",
    "        'strata': dset.strata\n",
    "    }\n",
    "\n",
    "    with open(f'/orcd/data/omarabu/001/Omnicell_datasets/repogle_k562_essential_raw/proportional_scot/synthetic_counterfactuals_{i}.pkl', 'wb') as f:\n",
    "        pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to synthetic_counterfactuals, source, and target to np.int16, also convert to sparse\n",
    "# from scipy import sparse\n",
    "\n",
    "# Convert synthetic counterfactuals to sparse\n",
    "synthetic_counterfactuals = {\n",
    "    stratum: {\n",
    "        pert: preds.astype(np.int16)\n",
    "        for pert, preds in synthetic_counterfactuals[stratum].items()\n",
    "    } \n",
    "    for stratum in synthetic_counterfactuals\n",
    "}\n",
    "\n",
    "# Convert source to sparse\n",
    "dset.source = {\n",
    "    stratum: source.astype(np.int16)\n",
    "    for stratum, source in dset.source.items()\n",
    "}\n",
    "\n",
    "# Convert target to sparse\n",
    "dset.target = {\n",
    "    stratum: {\n",
    "        pert: preds.astype(np.int16)\n",
    "        for pert, preds in dset.target[stratum].items()\n",
    "    } \n",
    "    for stratum in dset.target\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "import pickle\n",
    "# Save as before\n",
    "data_dict = {\n",
    "    'synthetic_counterfactuals': synthetic_counterfactuals,\n",
    "    'source': dset.source,\n",
    "    'target': dset.target,\n",
    "    'unique_pert_ids': dset.unique_pert_ids,\n",
    "    'strata': dset.strata\n",
    "}\n",
    "with open('/orcd/data/omarabu/001/Omnicell_datasets/repogle_k562_essential_raw/proportional_scot/synthetic_counterfactuals.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading\n",
    "import pickle\n",
    "with open('/orcd/data/omarabu/001/Omnicell_datasets/repogle_k562_essential_raw/proportional_scot/synthetic_counterfactuals.pkl', 'rb') as f:\n",
    "    data_dict = pickle.load(f)\n",
    "    \n",
    "synthetic_counterfactuals = data_dict['synthetic_counterfactuals']\n",
    "source = data_dict['source']\n",
    "target = data_dict['target']\n",
    "unique_pert_ids = data_dict['unique_pert_ids']\n",
    "strata = data_dict['strata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnicell",
   "language": "python",
   "name": "omnicell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
