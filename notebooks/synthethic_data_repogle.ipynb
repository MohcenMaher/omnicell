{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def generate_synthetic_perturbations(control_data, perturbed_data):\n",
    "    \"\"\"\n",
    "    Generate synthetic perturbed samples from control data while preserving the \n",
    "    mean expression and covariance structure of the true perturbed distribution.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    control_data : np.ndarray\n",
    "        Control population gene expression matrix (n_cells × n_genes)\n",
    "    perturbed_data : np.ndarray\n",
    "        Perturbed population gene expression matrix (m_cells × n_genes)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    synthetic_perturbed : np.ndarray\n",
    "        Synthetic perturbed samples with preserved statistics\n",
    "    transform_matrix : np.ndarray\n",
    "        The transformation matrix used to generate synthetic samples\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate means and covariances\n",
    "    control_mean = np.mean(control_data, axis=0)\n",
    "    perturbed_mean = np.mean(perturbed_data, axis=0)\n",
    "    \n",
    "    control_cov = np.cov(control_data.T)\n",
    "    perturbed_cov = np.cov(perturbed_data.T)\n",
    "    \n",
    "    # Ensure numerical stability\n",
    "    control_cov += 1e-10 * np.eye(control_cov.shape[0])\n",
    "    perturbed_cov += 1e-10 * np.eye(perturbed_cov.shape[0])\n",
    "    \n",
    "    # Calculate the transformation matrix using Cholesky decomposition\n",
    "    # This preserves the covariance structure\n",
    "    chol_control = linalg.cholesky(control_cov, lower=True)\n",
    "    chol_perturbed = linalg.cholesky(perturbed_cov, lower=True)\n",
    "    \n",
    "    # Calculate the transformation matrix\n",
    "    transform = np.dot(chol_perturbed, linalg.inv(chol_control))\n",
    "    \n",
    "    # Generate synthetic samples\n",
    "    centered_control = control_data - control_mean\n",
    "    synthetic_centered = np.dot(centered_control, transform.T)\n",
    "    synthetic_perturbed = synthetic_centered + perturbed_mean\n",
    "    \n",
    "    return synthetic_perturbed, transform\n",
    "\n",
    "def validate_synthetic_data(original_perturbed, synthetic_perturbed):\n",
    "    \"\"\"\n",
    "    Validate that the synthetic data preserves the statistical properties\n",
    "    of the original perturbed data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    original_perturbed : np.ndarray\n",
    "        Original perturbed population data\n",
    "    synthetic_perturbed : np.ndarray\n",
    "        Generated synthetic perturbed data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing validation metrics\n",
    "    \"\"\"\n",
    "    # Calculate validation metrics\n",
    "    orig_mean = np.mean(original_perturbed, axis=0)\n",
    "    synth_mean = np.mean(synthetic_perturbed, axis=0)\n",
    "    mean_diff = np.abs(orig_mean - synth_mean)\n",
    "    \n",
    "    orig_cov = np.cov(original_perturbed.T)\n",
    "    synth_cov = np.cov(synthetic_perturbed.T)\n",
    "    cov_diff = np.abs(orig_cov - synth_cov)\n",
    "    \n",
    "    metrics = {\n",
    "        'mean_difference_max': np.max(mean_diff),\n",
    "        'mean_difference_avg': np.mean(mean_diff),\n",
    "        'covariance_difference_max': np.max(cov_diff),\n",
    "        'covariance_difference_avg': np.mean(cov_diff)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Example usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perturbed data shape (1000, 100), perturbed data type float64\n",
      "Control data shape (1000, 100), control data type float64\n",
      "Validation metrics:\n",
      "mean_difference_max: 4.884981308350689e-15\n",
      "mean_difference_avg: 8.369867299240497e-16\n",
      "covariance_difference_max: 4.513955875751208e-11\n",
      "covariance_difference_avg: 9.131090768908179e-12\n"
     ]
    }
   ],
   "source": [
    "# Generate some example data\n",
    "n_genes = 100\n",
    "n_control_cells = 1000\n",
    "n_perturbed_cells = 800\n",
    "\n",
    "# Simulate control and perturbed data\n",
    "np.random.seed(42)\n",
    "control_data = np.random.normal(0, 1, (n_control_cells, n_genes))\n",
    "\n",
    "# Create perturbed data with different mean and covariance\n",
    "random_transform = np.random.normal(0, 0.1, (n_genes, n_genes))\n",
    "perturbed_data = np.dot(control_data, random_transform.T) + np.random.normal(1, 0.5, n_genes)\n",
    "\n",
    "print(f\"Perturbed data shape {perturbed_data.shape}, perturbed data type {perturbed_data.dtype}\")\n",
    "print(f\"Control data shape {control_data.shape}, control data type {control_data.dtype}\")\n",
    "\n",
    "# Generate synthetic perturbed samples\n",
    "synthetic_perturbed, transform = generate_synthetic_perturbations(control_data, perturbed_data)\n",
    "\n",
    "# Validate results\n",
    "metrics = validate_synthetic_data(perturbed_data, synthetic_perturbed)\n",
    "print(\"Validation metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "adata = sc.read('/orcd/data/omarabu/001/Omnicell_datasets/repogle_k562_essential_raw/K562_essential_raw_singlecell_01.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_data = adata[adata.obs[\"gene\"] == \"non-targeting\"].X.toarray().astype(np.float64)\n",
    "perturbed_data = adata[adata.obs[\"gene\"] == \"PCF11\"].X.toarray().astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_perturbed, transform = generate_synthetic_perturbations(control_data, perturbed_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10691, 8563)\n",
      "(10691, 8563)\n"
     ]
    }
   ],
   "source": [
    "print(synthetic_perturbed.shape)\n",
    "print(control_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics:\n",
      "mean_difference_max: 7.673861546209082e-13\n",
      "mean_difference_avg: 3.183176453944053e-15\n",
      "covariance_difference_max: 2.7816604415420443e-06\n",
      "covariance_difference_avg: 2.1535969161422817e-11\n"
     ]
    }
   ],
   "source": [
    "metrics = validate_synthetic_data(perturbed_data, synthetic_perturbed)\n",
    "print(\"Validation metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_adata = adata[adata.obs[\"gene\"] == \"non-targeting\"]\n",
    "gt_adata = adata[adata.obs[\"gene\"] == \"PCF11\"]\n",
    "\n",
    "synthetic_perturbed_adata = control_adata.copy()\n",
    "synthetic_perturbed_adata.X = synthetic_perturbed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16833667, 0.19438878, 1.52905812, ..., 0.25250501, 0.29058116,\n",
       "       0.2745491 ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_perturbed_adata.X.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.16833669, 0.19438884, 1.5290581 , ..., 0.25250503, 0.29058114,\n",
       "         0.27454913]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_adata.X.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orcd/data/omarabu/001/opitcho/miniforge3/envs/omnicell/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:406: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orcd/data/omarabu/001/opitcho/miniforge3/envs/omnicell/lib/python3.9/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "from omnicell.evaluation.utils import get_DEGs, get_DEGs_overlaps\n",
    "\n",
    "sc.pp.log1p(control_adata)\n",
    "pred_DEGs_df = get_DEGs(control_adata, synthetic_perturbed_adata)\n",
    "true_DEGs_df = get_DEGs(control_adata, gt_adata)\n",
    "\n",
    "DEGs_overlaps = get_DEGs_overlaps(true_DEGs_df, pred_DEGs_df, [100,50,20], 0.05, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Overlap_in_top_3677_DEGs': 2946,\n",
       " 'Overlap_in_top_100_DEGs': 88,\n",
       " 'Overlap_in_top_50_DEGs': 37,\n",
       " 'Overlap_in_top_20_DEGs': 14,\n",
       " 'Jaccard': 0.33774834437086093}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEGs_overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cell 0/10691\n",
      "Processing cell 1000/10691\n",
      "Processing cell 2000/10691\n",
      "Processing cell 3000/10691\n",
      "Processing cell 4000/10691\n",
      "Processing cell 5000/10691\n",
      "Processing cell 6000/10691\n",
      "Processing cell 7000/10691\n",
      "Processing cell 8000/10691\n",
      "Processing cell 9000/10691\n",
      "Processing cell 10000/10691\n",
      "Validation metrics:\n",
      "original_sparsity: 0.6219567477826141\n",
      "synthetic_sparsity: 0.7712065228809764\n",
      "original_integer: True\n",
      "synthetic_integer: True\n",
      "mean_difference: 0.47022226477160395\n",
      "unique_values: {'original': 527, 'synthetic': 499}\n",
      "Validation metrics:\n",
      "mean_difference_max: 34.66173278181094\n",
      "mean_difference_avg: 0.47022226477160395\n",
      "covariance_difference_max: 14225.801850900989\n",
      "covariance_difference_avg: 0.35706564419917314\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def generate_count_preserving_perturbations(control_data, perturbed_data, n_neighbors=20):\n",
    "    \"\"\"\n",
    "    Generate synthetic perturbed samples from control data while preserving\n",
    "    count structure, sparsity patterns, and statistical properties of the\n",
    "    true perturbed distribution.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    control_data : np.ndarray\n",
    "        Control population sparse count matrix (n_cells × n_genes)\n",
    "    perturbed_data : np.ndarray\n",
    "        Perturbed population sparse count matrix (m_cells × n_genes)\n",
    "    n_neighbors : int\n",
    "        Number of nearest neighbors to consider for sampling\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    synthetic_perturbed : np.ndarray\n",
    "        Synthetic perturbed samples with preserved count structure\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate statistical properties of perturbed data\n",
    "    perturbed_means = np.mean(perturbed_data, axis=0)\n",
    "    perturbed_vars = np.var(perturbed_data, axis=0)\n",
    "    \n",
    "    # Calculate sparsity patterns\n",
    "    perturbed_sparsity = (perturbed_data == 0).mean(axis=0)\n",
    "    \n",
    "    # Initialize synthetic data matrix\n",
    "    n_control = control_data.shape[0]\n",
    "    n_genes = control_data.shape[1]\n",
    "    synthetic_perturbed = np.zeros_like(control_data)\n",
    "    \n",
    "    # For each gene, transform the control counts while preserving structure\n",
    "    for gene_idx in range(n_genes):\n",
    "        control_gene = control_data[:, gene_idx]\n",
    "        perturbed_gene = perturbed_data[:, gene_idx]\n",
    "        \n",
    "        # Preserve sparsity pattern\n",
    "        control_nonzero = control_gene != 0\n",
    "        target_nonzero = np.random.random(n_control) > perturbed_sparsity[gene_idx]\n",
    "        \n",
    "        if np.sum(target_nonzero) > 0:\n",
    "            # For non-zero values, sample from empirical distribution\n",
    "            nonzero_counts = perturbed_gene[perturbed_gene != 0]\n",
    "            \n",
    "            if len(nonzero_counts) > 0:\n",
    "                # Sample counts from the empirical distribution\n",
    "                synthetic_counts = np.random.choice(\n",
    "                    nonzero_counts, \n",
    "                    size=np.sum(target_nonzero),\n",
    "                    replace=True\n",
    "                )\n",
    "                \n",
    "                # Assign sampled counts to non-zero positions\n",
    "                synthetic_perturbed[target_nonzero, gene_idx] = synthetic_counts\n",
    "    \n",
    "    # Adjust for local structure preservation\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')\n",
    "    nbrs.fit(perturbed_data)\n",
    "    \n",
    "    # Refine synthetic data using local structure\n",
    "    for cell_idx in range(n_control):\n",
    "        if cell_idx % 1000 == 0:  # Progress tracking\n",
    "            print(f\"Processing cell {cell_idx}/{n_control}\")\n",
    "            \n",
    "        cell_vector = synthetic_perturbed[cell_idx]\n",
    "        \n",
    "        # Find similar cells in perturbed data\n",
    "        distances, indices = nbrs.kneighbors(cell_vector.reshape(1, -1))\n",
    "        \n",
    "        # Sample from nearest neighbors for refinement\n",
    "        sampled_neighbor = perturbed_data[\n",
    "            indices[0][np.random.randint(0, len(indices[0]))]\n",
    "        ]\n",
    "        \n",
    "        # Adjust counts while preserving sparsity\n",
    "        nonzero_mask = synthetic_perturbed[cell_idx] != 0\n",
    "        if np.sum(nonzero_mask) > 0:\n",
    "            synthetic_perturbed[cell_idx, nonzero_mask] = np.minimum(\n",
    "                synthetic_perturbed[cell_idx, nonzero_mask],\n",
    "                sampled_neighbor[nonzero_mask]\n",
    "            )\n",
    "    \n",
    "    return synthetic_perturbed\n",
    "\n",
    "def validate_count_structure(original_perturbed, synthetic_perturbed):\n",
    "    \"\"\"\n",
    "    Validate that the synthetic data preserves count structure and sparsity.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    original_perturbed : np.ndarray\n",
    "        Original perturbed population data\n",
    "    synthetic_perturbed : np.ndarray\n",
    "        Generated synthetic perturbed data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing validation metrics\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'original_sparsity': (original_perturbed == 0).mean(),\n",
    "        'synthetic_sparsity': (synthetic_perturbed == 0).mean(),\n",
    "        'original_integer': np.all(np.equal(np.mod(original_perturbed, 1), 0)),\n",
    "        'synthetic_integer': np.all(np.equal(np.mod(synthetic_perturbed, 1), 0)),\n",
    "        'mean_difference': np.mean(np.abs(\n",
    "            np.mean(original_perturbed, axis=0) - \n",
    "            np.mean(synthetic_perturbed, axis=0)\n",
    "        )),\n",
    "        'unique_values': {\n",
    "            'original': len(np.unique(original_perturbed)),\n",
    "            'synthetic': len(np.unique(synthetic_perturbed))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "# Generate synthetic perturbed samples\n",
    "\n",
    "synthetic_perturbed = generate_count_preserving_perturbations(\n",
    "    control_data, \n",
    "    perturbed_data\n",
    ")\n",
    "\n",
    "\n",
    "# Validate results\n",
    "metrics = validate_count_structure(perturbed_data, synthetic_perturbed)\n",
    "print(\"Validation metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "    # Validate results\n",
    "metrics = validate_synthetic_data(perturbed_data, synthetic_perturbed)\n",
    "print(\"Validation metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_perturbed_sparsity_adata = control_adata.copy()\n",
    "synthetic_perturbed_sparsity_adata.X = synthetic_perturbed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02808893 0.03906319 1.07578913 ... 0.05606958 0.07404216 0.05969178]\n",
      "[0.05651246 0.10574827 0.33283934 ... 0.09893356 0.10239583 0.14217657]\n"
     ]
    }
   ],
   "source": [
    "print(synthetic_perturbed_sparsity_adata.X.var(axis=0))\n",
    "print(control_adata.X.toarray().var(axis=0))\n",
    "from omnicell.evaluation.utils import get_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orcd/data/omarabu/001/opitcho/miniforge3/envs/omnicell/lib/python3.9/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Overlap_in_top_3677_DEGs': 1001,\n",
       " 'Overlap_in_top_100_DEGs': 100,\n",
       " 'Overlap_in_top_50_DEGs': 47,\n",
       " 'Overlap_in_top_20_DEGs': 19,\n",
       " 'Jaccard': 0.13524590163934427}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred_DEGs_df = get_DEGs(control_adata, synthetic_perturbed_sparsity_adata)\n",
    "DEGs_overlaps = get_DEGs_overlaps(true_DEGs_df, pred_DEGs_df, [100,50,20], 0.05, None)\n",
    "\n",
    "DEGs_overlaps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_genes_mean_sub_diff_R': 0.9978958581455893,\n",
       " 'all_genes_mean_sub_diff_R2': 0.9957961437041222,\n",
       " 'all_genes_mean_sub_diff_MSE': 1.337547250628481,\n",
       " 'all_genes_mean_fold_diff_R': 0.9864283683293209,\n",
       " 'all_genes_mean_fold_diff_R2': 0.9730409258448464,\n",
       " 'all_genes_mean_fold_diff_MSE': 0.9764326740817398,\n",
       " 'all_genes_mean_R': 0.99861070275701,\n",
       " 'all_genes_mean_R2': 0.9972233356608494,\n",
       " 'all_genes_mean_MSE': 1.3375471037723647,\n",
       " 'all_genes_var_R': 0.9972929237480384,\n",
       " 'all_genes_var_R2': 0.9945931757579106,\n",
       " 'all_genes_var_MSE': 21991.493741236867,\n",
       " 'all_genes_corr_mtx_R': 0.7016891595993637,\n",
       " 'all_genes_corr_mtx_R2': 0.49236767669926135,\n",
       " 'all_genes_corr_mtx_MSE': 0.010289543702280723,\n",
       " 'all_genes_cov_mtx_R': 0.6086382565513448,\n",
       " 'all_genes_cov_mtx_R2': 0.37044052733786065,\n",
       " 'all_genes_cov_mtx_MSE': 79.31398266675811,\n",
       " 'Top_3677_DEGs_sub_diff_R': 0.9982916061354618,\n",
       " 'Top_3677_DEGs_sub_diff_R2': 0.99658613088052,\n",
       " 'Top_3677_DEGs_sub_diff_MSE': 3.0295415055729737,\n",
       " 'Top_3677_DEGs_fold_diff_R': 0.9925313079653497,\n",
       " 'Top_3677_DEGs_fold_diff_R2': 0.9851183972914079,\n",
       " 'Top_3677_DEGs_fold_diff_MSE': 0.921445274372157,\n",
       " 'Top_3677_DEGs_mean_R': 0.998806411927695,\n",
       " 'Top_3677_DEGs_mean_R2': 0.9976142485078764,\n",
       " 'Top_3677_DEGs_mean_MSE': 3.0295411635777745,\n",
       " 'Top_3677_DEGs_var_R': 0.9972937616613725,\n",
       " 'Top_3677_DEGs_var_R2': 0.9945948470486905,\n",
       " 'Top_3677_DEGs_var_MSE': 51213.57081089911,\n",
       " 'Top_3677_DEGs_corr_mtx_R': 0.7470414615698124,\n",
       " 'Top_3677_DEGs_corr_mtx_R2': 0.5580709453043615,\n",
       " 'Top_3677_DEGs_corr_mtx_MSE': 0.022717419118439705,\n",
       " 'Top_3677_DEGs_cov_mtx_R': 0.6087633200589057,\n",
       " 'Top_3677_DEGs_cov_mtx_R2': 0.37059277984914163,\n",
       " 'Top_3677_DEGs_cov_mtx_MSE': 428.0544957478818,\n",
       " 'Top_100_DEGs_sub_diff_R': 0.999383844427671,\n",
       " 'Top_100_DEGs_sub_diff_R2': 0.9987680685030313,\n",
       " 'Top_100_DEGs_sub_diff_MSE': 87.0088121785233,\n",
       " 'Top_100_DEGs_fold_diff_R': 0.9991278886582722,\n",
       " 'Top_100_DEGs_fold_diff_R2': 0.9982565378947367,\n",
       " 'Top_100_DEGs_fold_diff_MSE': 4.602095220795865,\n",
       " 'Top_100_DEGs_mean_R': 0.9994196809765697,\n",
       " 'Top_100_DEGs_mean_R2': 0.9988396987233085,\n",
       " 'Top_100_DEGs_mean_MSE': 87.00879959787594,\n",
       " 'Top_100_DEGs_var_R': 0.9973563430660212,\n",
       " 'Top_100_DEGs_var_R2': 0.9947196750540269,\n",
       " 'Top_100_DEGs_var_MSE': 1876764.7518961767,\n",
       " 'Top_100_DEGs_corr_mtx_R': 0.4879294762160107,\n",
       " 'Top_100_DEGs_corr_mtx_R2': 0.23807517376043053,\n",
       " 'Top_100_DEGs_corr_mtx_MSE': 0.34801884360824265,\n",
       " 'Top_100_DEGs_cov_mtx_R': 0.6032423652727679,\n",
       " 'Top_100_DEGs_cov_mtx_R2': 0.3639013512598835,\n",
       " 'Top_100_DEGs_cov_mtx_MSE': 496629.6682977337,\n",
       " 'Top_50_DEGs_sub_diff_R': 0.9995567999784816,\n",
       " 'Top_50_DEGs_sub_diff_R2': 0.9991137963832222,\n",
       " 'Top_50_DEGs_sub_diff_MSE': 138.41717724899047,\n",
       " 'Top_50_DEGs_fold_diff_R': 0.9993393698634798,\n",
       " 'Top_50_DEGs_fold_diff_R2': 0.9986791761591369,\n",
       " 'Top_50_DEGs_fold_diff_MSE': 6.525074247042629,\n",
       " 'Top_50_DEGs_mean_R': 0.9995745522975612,\n",
       " 'Top_50_DEGs_mean_R2': 0.9991492856008699,\n",
       " 'Top_50_DEGs_mean_MSE': 138.41715393128914,\n",
       " 'Top_50_DEGs_var_R': 0.9972739744493364,\n",
       " 'Top_50_DEGs_var_R2': 0.9945553801139757,\n",
       " 'Top_50_DEGs_var_MSE': 3701009.911411675,\n",
       " 'Top_50_DEGs_corr_mtx_R': 0.5108826805619382,\n",
       " 'Top_50_DEGs_corr_mtx_R2': 0.2610011132981514,\n",
       " 'Top_50_DEGs_corr_mtx_MSE': 0.37811970080766616,\n",
       " 'Top_50_DEGs_cov_mtx_R': 0.623689289965842,\n",
       " 'Top_50_DEGs_cov_mtx_R2': 0.3889883304180962,\n",
       " 'Top_50_DEGs_cov_mtx_MSE': 1474313.6162975319,\n",
       " 'Top_20_DEGs_sub_diff_R': 0.9993086505554631,\n",
       " 'Top_20_DEGs_sub_diff_R2': 0.9986177790749807,\n",
       " 'Top_20_DEGs_sub_diff_MSE': 193.85152323848857,\n",
       " 'Top_20_DEGs_fold_diff_R': 0.998947481138422,\n",
       " 'Top_20_DEGs_fold_diff_R2': 0.997896070072798,\n",
       " 'Top_20_DEGs_fold_diff_MSE': 8.652040309506187,\n",
       " 'Top_20_DEGs_mean_R': 0.9993284040156714,\n",
       " 'Top_20_DEGs_mean_R2': 0.9986572590725089,\n",
       " 'Top_20_DEGs_mean_MSE': 193.85150420233333,\n",
       " 'Top_20_DEGs_var_R': 0.9917530338579801,\n",
       " 'Top_20_DEGs_var_R2': 0.9835740801665078,\n",
       " 'Top_20_DEGs_var_MSE': 3918611.670345798,\n",
       " 'Top_20_DEGs_corr_mtx_R': 0.5362782325585913,\n",
       " 'Top_20_DEGs_corr_mtx_R2': 0.2875943427161665,\n",
       " 'Top_20_DEGs_corr_mtx_MSE': 0.3682154527440676,\n",
       " 'Top_20_DEGs_cov_mtx_R': 0.6535155954021503,\n",
       " 'Top_20_DEGs_cov_mtx_R2': 0.427082633433827,\n",
       " 'Top_20_DEGs_cov_mtx_MSE': 2602762.1929762084}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_eval(control_adata, gt_adata, synthetic_perturbed_sparsity_adata, true_DEGs_df, [100,50,20], 0.05, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_genes_mean_sub_diff_R': 0.9999999999999994,\n",
       " 'all_genes_mean_sub_diff_R2': 0.9999999999999989,\n",
       " 'all_genes_mean_sub_diff_MSE': 6.506598652215286e-14,\n",
       " 'all_genes_mean_fold_diff_R': 0.999999999999999,\n",
       " 'all_genes_mean_fold_diff_R2': 0.999999999999998,\n",
       " 'all_genes_mean_fold_diff_MSE': 4.9403403383518756e-15,\n",
       " 'all_genes_mean_R': 0.9999999999999998,\n",
       " 'all_genes_mean_R2': 0.9999999999999996,\n",
       " 'all_genes_mean_MSE': 1.7246822772324387e-14,\n",
       " 'all_genes_var_R': 0.9999999999999997,\n",
       " 'all_genes_var_R2': 0.9999999999999993,\n",
       " 'all_genes_var_MSE': 0.3735949021463976,\n",
       " 'all_genes_corr_mtx_R': 1.0,\n",
       " 'all_genes_corr_mtx_R2': 1.0,\n",
       " 'all_genes_corr_mtx_MSE': 6.732789410295028e-22,\n",
       " 'all_genes_cov_mtx_R': 1.0,\n",
       " 'all_genes_cov_mtx_R2': 1.0,\n",
       " 'all_genes_cov_mtx_MSE': 7.168730001909094e-19,\n",
       " 'Top_3677_DEGs_sub_diff_R': 0.9999999999999996,\n",
       " 'Top_3677_DEGs_sub_diff_R2': 0.9999999999999991,\n",
       " 'Top_3677_DEGs_sub_diff_MSE': 1.5138807656079068e-13,\n",
       " 'Top_3677_DEGs_fold_diff_R': 0.9999999999999991,\n",
       " 'Top_3677_DEGs_fold_diff_R2': 0.9999999999999982,\n",
       " 'Top_3677_DEGs_fold_diff_MSE': 8.468076387937779e-15,\n",
       " 'Top_3677_DEGs_mean_R': 0.9999999999999999,\n",
       " 'Top_3677_DEGs_mean_R2': 0.9999999999999998,\n",
       " 'Top_3677_DEGs_mean_MSE': 4.002681486691152e-14,\n",
       " 'Top_3677_DEGs_var_R': 0.9999999999999993,\n",
       " 'Top_3677_DEGs_var_R2': 0.9999999999999987,\n",
       " 'Top_3677_DEGs_var_MSE': 0.8700263443498134,\n",
       " 'Top_3677_DEGs_corr_mtx_R': 1.0,\n",
       " 'Top_3677_DEGs_corr_mtx_R2': 1.0,\n",
       " 'Top_3677_DEGs_corr_mtx_MSE': 7.515495282238912e-22,\n",
       " 'Top_3677_DEGs_cov_mtx_R': 1.0,\n",
       " 'Top_3677_DEGs_cov_mtx_R2': 1.0,\n",
       " 'Top_3677_DEGs_cov_mtx_MSE': 3.879953645504907e-18,\n",
       " 'Top_100_DEGs_sub_diff_R': 0.9999999999999992,\n",
       " 'Top_100_DEGs_sub_diff_R2': 0.9999999999999984,\n",
       " 'Top_100_DEGs_sub_diff_MSE': 5.257746064856365e-12,\n",
       " 'Top_100_DEGs_fold_diff_R': 0.9999999999999991,\n",
       " 'Top_100_DEGs_fold_diff_R2': 0.9999999999999982,\n",
       " 'Top_100_DEGs_fold_diff_MSE': 1.6707265000992504e-13,\n",
       " 'Top_100_DEGs_mean_R': 0.9999999999999999,\n",
       " 'Top_100_DEGs_mean_R2': 0.9999999999999998,\n",
       " 'Top_100_DEGs_mean_MSE': 1.2866750706195034e-12,\n",
       " 'Top_100_DEGs_var_R': 0.9999999999999997,\n",
       " 'Top_100_DEGs_var_R2': 0.9999999999999993,\n",
       " 'Top_100_DEGs_var_MSE': 31.935139921825403,\n",
       " 'Top_100_DEGs_corr_mtx_R': 0.9999999999999999,\n",
       " 'Top_100_DEGs_corr_mtx_R2': 0.9999999999999998,\n",
       " 'Top_100_DEGs_corr_mtx_MSE': 1.6401682771758589e-21,\n",
       " 'Top_100_DEGs_cov_mtx_R': 0.9999999999999999,\n",
       " 'Top_100_DEGs_cov_mtx_R2': 0.9999999999999998,\n",
       " 'Top_100_DEGs_cov_mtx_MSE': 5.0608175334859106e-15,\n",
       " 'Top_50_DEGs_sub_diff_R': 0.9999999999999993,\n",
       " 'Top_50_DEGs_sub_diff_R2': 0.9999999999999987,\n",
       " 'Top_50_DEGs_sub_diff_MSE': 9.742179354636389e-12,\n",
       " 'Top_50_DEGs_fold_diff_R': 0.9999999999999991,\n",
       " 'Top_50_DEGs_fold_diff_R2': 0.9999999999999982,\n",
       " 'Top_50_DEGs_fold_diff_MSE': 2.651228719711929e-13,\n",
       " 'Top_50_DEGs_mean_R': 0.9999999999999997,\n",
       " 'Top_50_DEGs_mean_R2': 0.9999999999999993,\n",
       " 'Top_50_DEGs_mean_MSE': 2.089970697666404e-12,\n",
       " 'Top_50_DEGs_var_R': 0.9999999999999994,\n",
       " 'Top_50_DEGs_var_R2': 0.9999999999999989,\n",
       " 'Top_50_DEGs_var_MSE': 63.15345839919736,\n",
       " 'Top_50_DEGs_corr_mtx_R': 1.0,\n",
       " 'Top_50_DEGs_corr_mtx_R2': 1.0,\n",
       " 'Top_50_DEGs_corr_mtx_MSE': 1.4494524641806194e-21,\n",
       " 'Top_50_DEGs_cov_mtx_R': 1.0,\n",
       " 'Top_50_DEGs_cov_mtx_R2': 1.0,\n",
       " 'Top_50_DEGs_cov_mtx_MSE': 1.8884058490456855e-14,\n",
       " 'Top_20_DEGs_sub_diff_R': 0.9999999999999994,\n",
       " 'Top_20_DEGs_sub_diff_R2': 0.9999999999999989,\n",
       " 'Top_20_DEGs_sub_diff_MSE': 5.9463986889475025e-12,\n",
       " 'Top_20_DEGs_fold_diff_R': 0.9999999999999987,\n",
       " 'Top_20_DEGs_fold_diff_R2': 0.9999999999999973,\n",
       " 'Top_20_DEGs_fold_diff_MSE': 3.789731993653713e-13,\n",
       " 'Top_20_DEGs_mean_R': 0.9999999999999997,\n",
       " 'Top_20_DEGs_mean_R2': 0.9999999999999993,\n",
       " 'Top_20_DEGs_mean_MSE': 2.8678320277751977e-12,\n",
       " 'Top_20_DEGs_var_R': 0.9999999999999987,\n",
       " 'Top_20_DEGs_var_R2': 0.9999999999999973,\n",
       " 'Top_20_DEGs_var_MSE': 61.82004235436368,\n",
       " 'Top_20_DEGs_corr_mtx_R': 1.0,\n",
       " 'Top_20_DEGs_corr_mtx_R2': 1.0,\n",
       " 'Top_20_DEGs_corr_mtx_MSE': 1.476455737152845e-21,\n",
       " 'Top_20_DEGs_cov_mtx_R': 1.0,\n",
       " 'Top_20_DEGs_cov_mtx_R2': 1.0,\n",
       " 'Top_20_DEGs_cov_mtx_MSE': 3.705625721540852e-14}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_eval(control_adata, gt_adata, synthetic_perturbed_adata, true_DEGs_df, [100,50,20], 0.05, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnicell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
