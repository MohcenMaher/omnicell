{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "import scvi\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "\n",
    "import scanpy as sc\n",
    "\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from datamodules import FMDataset, fm_collate, CFMDataset, SCFMDataset, cfm_collate, StratifiedBatchSampler, ot_collate\n",
    "from torch.utils.data import RandomSampler\n",
    "from sc_etl_utils import *\n",
    "from arch import *\n",
    "from flow_utils import compute_conditional_flow\n",
    "import json\n",
    "\n",
    "import scvi\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "\n",
    "import scanpy as sc\n",
    "\n",
    "from torchcfm.conditional_flow_matching import *\n",
    "import scanpy as sc\n",
    "import hashlib\n",
    "from llm import MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some data\n",
    "adata = sc.read_h5ad('/orcd/archive/abugoot/001/Projects/dlesman/datasets/satija_IFNB_HVG_and_perturbed_genes_raw.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_map = {'NT': 0} | {k: i for i, k in enumerate(adata.var.index)}\n",
    "gene_unmap = {gene_map[k]: k for k in gene_map}\n",
    "perts = adata.obs.gene.unique().map(gene_map)\n",
    "adata.obs['pert_type'] = adata.obs.gene.map(gene_map)\n",
    "pert_ids = np.array(adata.obs['pert_type'])\n",
    "pert_mat = np.arange(pert_ids.max() + 1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_col = 'cell_type'\n",
    "pert_col = 'pert_type'\n",
    "control_pert, holdout_cells, holdout_perts = 0, ['HT29'], [gene_map['USP18']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 14582, Perturbations: 313080,  Eval: 880\n"
     ]
    }
   ],
   "source": [
    "from sc_etl_utils import *\n",
    "control_idx, pert_idx, eval_idx, eval_cell_idx, eval_pert_idx = get_train_eval_idxs(\n",
    "    adata, control_pert, holdout_cells, holdout_perts, cell_col=cell_col, pert_col=pert_col\n",
    ")\n",
    "\n",
    "_, _, cell_types = get_identity_features(\n",
    "    adata, cell_col=cell_col, pert_col=pert_col, cell_type_features=False\n",
    ")\n",
    "\n",
    "adata.obsm[\"standard\"] = adata.X\n",
    "X = adata.obsm[\"standard\"]\n",
    "X = X.toarray()\n",
    "X = X / X.sum(axis=1)[:, None]\n",
    "\n",
    "control_train, pert_train, pert_ids_train, control_cell_types, pert_cell_types, control_eval, pert_eval, pert_ids_eval = get_train_eval(\n",
    "    X, pert_ids, cell_types, control_idx, pert_idx, eval_idx, eval_cell_idx, eval_pert_idx\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "base_learning_rate = 5e-5\n",
    "weight_decay=0.0\n",
    "total_epoch = 5000\n",
    "warmup_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09837271 0.2565357  0.2074058  0.17077354 0.08714468 0.17976757]\n"
     ]
    }
   ],
   "source": [
    "dset = SCFMDataset(\n",
    "    control_train, pert_train, \n",
    "    pert_ids_train, pert_mat, \n",
    "    control_cell_types, pert_cell_types,\n",
    "    batch_size=batch_size, size=X.shape[0]\n",
    ")\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    dset, collate_fn=ot_collate, \n",
    "    batch_sampler=StratifiedBatchSampler(\n",
    "        RandomSampler(dset), batch_size=batch_size, drop_last=True, \n",
    "        probs=dset.probs, num_strata=dset.num_strata\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MAE(X.shape[1])\n",
    "model = torch.load(f\"transformer_v4.1\")\n",
    "device = 'cuda'\n",
    "# device = 'cpu'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "base_learning_rate = 5e-4\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=base_learning_rate, betas=(0.9, 0.95), weight_decay=weight_decay)\n",
    "lr_func = lambda epoch: min((epoch + 1) / (warmup_epoch + 1e-5), 0.5 * (math.cos(epoch / total_epoch * math.pi) + 1))\n",
    "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=lr_func, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 2375.500, mtv: 2534.008:   4%|█████▊                                                                                                                                              | 25/641 [03:06<1:16:42,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 2352.649, mtv: 2357.580:   8%|███████████▌                                                                                                                                        | 50/641 [06:13<1:13:37,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 2321.391, mtv: 2319.175:  12%|█████████████████▎                                                                                                                                  | 75/641 [09:20<1:10:36,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 2209.935, mtv: 2228.188:  16%|██████████████████████▉                                                                                                                            | 100/641 [12:27<1:07:34,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 2091.857, mtv: 2117.020:  20%|████████████████████████████▋                                                                                                                      | 125/641 [15:35<1:04:28,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 2128.629, mtv: 2139.694:  23%|██████████████████████████████████▍                                                                                                                | 150/641 [18:42<1:01:17,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 2067.227, mtv: 2106.164:  27%|████████████████████████████████████████▋                                                                                                            | 175/641 [21:49<58:11,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 2002.322, mtv: 2058.918:  31%|██████████████████████████████████████████████▍                                                                                                      | 200/641 [24:57<55:01,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1929.530, mtv: 1990.988:  35%|████████████████████████████████████████████████████▎                                                                                                | 225/641 [28:04<51:55,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1795.604, mtv: 1863.557:  39%|██████████████████████████████████████████████████████████                                                                                           | 250/641 [31:11<48:51,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1737.285, mtv: 1811.008:  43%|███████████████████████████████████████████████████████████████▉                                                                                     | 275/641 [34:19<45:44,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1690.752, mtv: 1771.220:  47%|█████████████████████████████████████████████████████████████████████▋                                                                               | 300/641 [37:26<42:36,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1599.470, mtv: 1689.159:  51%|███████████████████████████████████████████████████████████████████████████▌                                                                         | 325/641 [40:33<39:30,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1609.826, mtv: 1692.800:  55%|█████████████████████████████████████████████████████████████████████████████████▎                                                                   | 350/641 [43:41<36:22,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1530.161, mtv: 1607.478:  59%|███████████████████████████████████████████████████████████████████████████████████████▏                                                             | 375/641 [46:48<33:12,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1501.321, mtv: 1564.812:  62%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 400/641 [49:56<30:07,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1499.167, mtv: 1557.039:  66%|██████████████████████████████████████████████████████████████████████████████████████████████████▊                                                  | 425/641 [53:03<26:54,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1451.239, mtv: 1520.650:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                            | 450/641 [56:10<23:48,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9998e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1439.644, mtv: 1501.781:  74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 475/641 [59:17<20:41,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9998e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1355.519, mtv: 1425.451:  78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                | 500/641 [1:02:24<17:37,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9998e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1372.677, mtv: 1430.969:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 525/641 [1:05:31<14:30,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9998e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1371.474, mtv: 1436.525:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 550/641 [1:08:39<11:22,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9998e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1348.574, mtv: 1405.878:  90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊               | 575/641 [1:11:46<08:15,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9997e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1342.950, mtv: 1399.440:  94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌         | 600/641 [1:14:54<05:07,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9997e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1388.473, mtv: 1427.563:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎   | 625/641 [1:18:02<02:00,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9997e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1335.551, mtv: 1379.721: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 641/641 [1:20:02<00:00,  7.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, average traning loss is 1729.610626934843.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1409.355, mtv: 1460.160:   1%|██                                                                                                                                                   | 9/641 [01:07<1:19:00,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9997e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1339.509, mtv: 1381.626:   5%|███████▊                                                                                                                                            | 34/641 [04:14<1:15:49,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9996e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1300.292, mtv: 1343.679:   9%|█████████████▌                                                                                                                                      | 59/641 [07:22<1:12:45,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9996e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1281.801, mtv: 1330.498:  13%|███████████████████▍                                                                                                                                | 84/641 [10:30<1:09:38,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9996e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1316.460, mtv: 1365.705:  17%|████████████████████████▉                                                                                                                          | 109/641 [13:37<1:06:30,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9996e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1321.532, mtv: 1372.397:  21%|██████████████████████████████▋                                                                                                                    | 134/641 [16:45<1:03:20,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9995e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1283.136, mtv: 1332.661:  25%|████████████████████████████████████▍                                                                                                              | 159/641 [19:52<1:00:20,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9995e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1283.887, mtv: 1329.986:  29%|██████████████████████████████████████████▊                                                                                                          | 184/641 [23:00<57:09,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9995e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1305.545, mtv: 1358.564:  33%|████████████████████████████████████████████████▌                                                                                                    | 209/641 [26:07<53:57,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9994e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1246.334, mtv: 1299.273:  37%|██████████████████████████████████████████████████████▍                                                                                              | 234/641 [29:15<50:50,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9994e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1234.410, mtv: 1294.195:  40%|████████████████████████████████████████████████████████████▏                                                                                        | 259/641 [32:22<47:43,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9994e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1271.652, mtv: 1324.150:  44%|██████████████████████████████████████████████████████████████████                                                                                   | 284/641 [35:30<44:36,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9993e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1287.826, mtv: 1340.654:  48%|███████████████████████████████████████████████████████████████████████▊                                                                             | 309/641 [38:37<41:27,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9993e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1316.253, mtv: 1364.869:  52%|█████████████████████████████████████████████████████████████████████████████▋                                                                       | 334/641 [41:44<38:19,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9992e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1319.763, mtv: 1364.263:  56%|███████████████████████████████████████████████████████████████████████████████████▍                                                                 | 359/641 [44:51<35:12,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9992e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1230.192, mtv: 1281.925:  60%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                           | 384/641 [47:59<32:04,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9992e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1263.446, mtv: 1311.589:  64%|███████████████████████████████████████████████████████████████████████████████████████████████                                                      | 409/641 [51:06<28:57,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9991e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1368.918, mtv: 1415.381:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                | 434/641 [54:13<25:50,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9991e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1299.676, mtv: 1348.347:  72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                          | 459/641 [57:20<22:44,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9990e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1292.256, mtv: 1341.767:  76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 484/641 [1:00:28<19:36,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9990e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1281.329, mtv: 1327.241:  79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 509/641 [1:03:35<16:27,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9990e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1313.996, mtv: 1360.059:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 534/641 [1:06:42<13:21,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9989e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1255.935, mtv: 1304.557:  87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                  | 559/641 [1:09:49<10:13,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9989e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1322.157, mtv: 1369.274:  91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉             | 584/641 [1:12:56<07:06,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9988e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1273.395, mtv: 1324.294:  95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋       | 609/641 [1:16:03<03:59,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9988e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1250.413, mtv: 1305.980:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 634/641 [1:19:11<00:52,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9987e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1263.740, mtv: 1312.596: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 641/641 [1:20:03<00:00,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 1, average traning loss is 1292.4689273447402.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "step_count = 0\n",
    "optim.zero_grad()\n",
    "pert_task = 0\n",
    "for e in range(2):\n",
    "    model.train()\n",
    "    losses = {(0, 0): [], (0, 1): [], (1, 0): [], (1, 1): []}\n",
    "    for (bcontrol, bpert, bpert_index) in (pbar := tqdm(iter(dl))):\n",
    "        for i in range(batch_size // minibatch_size):\n",
    "            control = bcontrol[(i * minibatch_size):((i + 1) * minibatch_size)]\n",
    "            pert = bpert[(i * minibatch_size):((i + 1) * minibatch_size)]\n",
    "            pert_index = bpert_index[(i * minibatch_size):((i + 1) * minibatch_size)]\n",
    "            \n",
    "            control_sparsity = (control > 0).float().to(device)\n",
    "            active_weights = 10 * control_sparsity + 1\n",
    "            control = control.float().to(device)\n",
    "            pert = pert.float().to(device)\n",
    "            step_count += 1\n",
    "            mask_task = step_count % 2\n",
    "            control_recon, sparsity_probs, _ = model(control, mask=mask_task)\n",
    "            loss = torch.sum(active_weights * torch.abs(control_recon - control)) / minibatch_size\n",
    "            loss += torch.sum(active_weights * torch.abs(control_sparsity - sparsity_probs)) / minibatch_size\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            losses[(pert_task, mask_task)].append(loss.item())\n",
    "        if step_count % 100 == 0:\n",
    "            lr_scheduler.step()\n",
    "        if pert_task == 0 and mask_task == 0:\n",
    "            pbar.set_description(\n",
    "                f\"tv: {np.array(losses[(0, 0)])[-100:].mean():.3f}, mtv: {np.array(losses[(0, 1)])[-100:].mean():.3f}\")\n",
    "    \n",
    "    avg_loss = sum(losses[(0, 0)]) / len(losses[(0, 0)])\n",
    "    torch.save(model, f\"transformer_v3.{e}\")\n",
    "    # writer.add_scalar('mae_loss', avg_loss, global_step=e)\n",
    "    print(f'In epoch {e}, average traning loss is {avg_loss}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 5.643, mtv: 8.000, ptv: 6.444, pmtv: 7.107:   4%|█████                                                                                                                            | 25/641 [03:14<1:19:56,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 5.461, mtv: 7.930, ptv: 6.438, pmtv: 7.193:   8%|██████████                                                                                                                       | 50/641 [06:29<1:16:48,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 5.242, mtv: 7.858, ptv: 6.420, pmtv: 7.264:  12%|███████████████                                                                                                                  | 75/641 [09:43<1:13:21,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 5.175, mtv: 7.792, ptv: 6.381, pmtv: 7.190:  16%|███████████████████▉                                                                                                            | 100/641 [12:57<1:09:43,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 5.094, mtv: 7.654, ptv: 6.326, pmtv: 7.077:  20%|████████████████████████▉                                                                                                       | 125/641 [16:10<1:06:26,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 5.053, mtv: 7.703, ptv: 6.331, pmtv: 7.116:  23%|█████████████████████████████▉                                                                                                  | 150/641 [19:24<1:03:34,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 5.167, mtv: 7.884, ptv: 6.383, pmtv: 7.194:  27%|██████████████████████████████████▉                                                                                             | 175/641 [22:38<1:00:29,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 5.184, mtv: 7.879, ptv: 6.382, pmtv: 7.143:  31%|████████████████████████████████████████▌                                                                                         | 200/641 [25:53<57:08,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.958, mtv: 7.741, ptv: 6.349, pmtv: 7.127:  35%|█████████████████████████████████████████████▋                                                                                    | 225/641 [29:07<53:50,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.789, mtv: 7.669, ptv: 6.312, pmtv: 7.135:  39%|██████████████████████████████████████████████████▋                                                                               | 250/641 [32:21<50:29,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.755, mtv: 7.678, ptv: 6.292, pmtv: 7.135:  43%|███████████████████████████████████████████████████████▊                                                                          | 275/641 [35:35<47:13,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.783, mtv: 7.743, ptv: 6.316, pmtv: 7.223:  47%|████████████████████████████████████████████████████████████▊                                                                     | 300/641 [38:48<43:54,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.669, mtv: 7.653, ptv: 6.308, pmtv: 7.214:  51%|█████████████████████████████████████████████████████████████████▉                                                                | 325/641 [42:01<40:41,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.715, mtv: 7.633, ptv: 6.294, pmtv: 7.111:  55%|██████████████████████████████████████████████████████████████████████▉                                                           | 350/641 [45:15<37:39,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.773, mtv: 7.764, ptv: 6.282, pmtv: 7.187:  59%|████████████████████████████████████████████████████████████████████████████                                                      | 375/641 [48:29<34:29,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.572, mtv: 7.654, ptv: 6.264, pmtv: 7.144:  62%|█████████████████████████████████████████████████████████████████████████████████                                                 | 400/641 [51:44<31:16,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.388, mtv: 7.562, ptv: 6.224, pmtv: 7.058:  66%|██████████████████████████████████████████████████████████████████████████████████████▏                                           | 425/641 [54:59<28:03,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.353, mtv: 7.623, ptv: 6.193, pmtv: 7.132:  70%|███████████████████████████████████████████████████████████████████████████████████████████▎                                      | 450/641 [58:13<24:48,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9998e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.370, mtv: 7.516, ptv: 6.187, pmtv: 7.021:  74%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                 | 475/641 [1:01:28<21:27,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9998e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.350, mtv: 7.490, ptv: 6.214, pmtv: 7.015:  78%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 500/641 [1:04:41<18:12,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9998e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.288, mtv: 7.543, ptv: 6.219, pmtv: 7.069:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 525/641 [1:07:55<14:56,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9998e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.082, mtv: 7.383, ptv: 6.154, pmtv: 6.983:  86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 550/641 [1:11:08<11:44,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9998e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.029, mtv: 7.368, ptv: 6.167, pmtv: 7.029:  90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 575/641 [1:14:22<08:32,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9997e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.132, mtv: 7.489, ptv: 6.228, pmtv: 7.102:  94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊        | 600/641 [1:17:36<05:19,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9997e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.181, mtv: 7.562, ptv: 6.232, pmtv: 7.101:  98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 625/641 [1:20:51<02:04,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9997e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.072, mtv: 7.492, ptv: 6.179, pmtv: 7.113: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 641/641 [1:22:56<00:00,  7.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, average traning loss is 4.677812644360404.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 4.157, mtv: 7.347, ptv: 6.175, pmtv: 6.793:   1%|█▊                                                                                                                                | 9/641 [01:09<1:21:51,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9997e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.863, mtv: 7.341, ptv: 6.137, pmtv: 6.958:   5%|██████▊                                                                                                                          | 34/641 [04:24<1:18:28,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9996e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.852, mtv: 7.397, ptv: 6.160, pmtv: 7.039:   9%|███████████▊                                                                                                                     | 59/641 [07:38<1:15:14,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9996e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.886, mtv: 7.469, ptv: 6.167, pmtv: 7.108:  13%|████████████████▉                                                                                                                | 84/641 [10:52<1:11:55,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9996e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.895, mtv: 7.524, ptv: 6.168, pmtv: 7.132:  17%|█████████████████████▊                                                                                                          | 109/641 [14:06<1:08:45,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9996e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.814, mtv: 7.422, ptv: 6.181, pmtv: 7.100:  21%|██████████████████████████▊                                                                                                     | 134/641 [17:21<1:05:25,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9995e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.658, mtv: 7.339, ptv: 6.134, pmtv: 7.121:  25%|███████████████████████████████▊                                                                                                | 159/641 [20:35<1:02:23,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9995e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.674, mtv: 7.397, ptv: 6.142, pmtv: 7.130:  29%|█████████████████████████████████████▎                                                                                            | 184/641 [23:49<59:15,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9995e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.857, mtv: 7.490, ptv: 6.202, pmtv: 7.089:  33%|██████████████████████████████████████████▍                                                                                       | 209/641 [27:05<57:36,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9994e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.804, mtv: 7.402, ptv: 6.180, pmtv: 6.995:  37%|███████████████████████████████████████████████▍                                                                                  | 234/641 [30:20<52:39,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9994e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.605, mtv: 7.307, ptv: 6.134, pmtv: 6.996:  40%|████████████████████████████████████████████████████▌                                                                             | 259/641 [33:37<50:30,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9994e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.592, mtv: 7.359, ptv: 6.107, pmtv: 7.095:  44%|█████████████████████████████████████████████████████████▌                                                                        | 284/641 [36:55<47:11,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9993e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.600, mtv: 7.358, ptv: 6.138, pmtv: 7.082:  48%|██████████████████████████████████████████████████████████████▋                                                                   | 309/641 [40:11<42:59,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9993e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.482, mtv: 7.197, ptv: 6.119, pmtv: 6.948:  52%|███████████████████████████████████████████████████████████████████▋                                                              | 334/641 [43:25<39:38,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9992e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.397, mtv: 7.173, ptv: 6.071, pmtv: 6.955:  56%|████████████████████████████████████████████████████████████████████████▊                                                         | 359/641 [46:39<36:30,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9992e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.478, mtv: 7.353, ptv: 6.115, pmtv: 7.087:  60%|█████████████████████████████████████████████████████████████████████████████▉                                                    | 384/641 [49:53<33:25,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9992e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.446, mtv: 7.303, ptv: 6.132, pmtv: 7.093:  64%|██████████████████████████████████████████████████████████████████████████████████▉                                               | 409/641 [53:09<30:10,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9991e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.377, mtv: 7.223, ptv: 6.113, pmtv: 7.053:  68%|████████████████████████████████████████████████████████████████████████████████████████                                          | 434/641 [56:24<26:53,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9991e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.302, mtv: 7.116, ptv: 6.075, pmtv: 6.925:  72%|█████████████████████████████████████████████████████████████████████████████████████████████                                     | 459/641 [59:38<23:33,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9990e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.378, mtv: 7.172, ptv: 6.116, pmtv: 6.956:  76%|████████████████████████████████████████████████████████████████████████████████████████████████▋                               | 484/641 [1:02:53<20:24,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9990e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.388, mtv: 7.280, ptv: 6.132, pmtv: 7.127:  79%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 509/641 [1:06:08<17:10,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9990e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.273, mtv: 7.218, ptv: 6.062, pmtv: 7.066:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                     | 534/641 [1:09:26<14:05,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9989e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.359, mtv: 7.291, ptv: 6.087, pmtv: 7.046:  87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 559/641 [1:12:43<10:50,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9989e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.363, mtv: 7.225, ptv: 6.134, pmtv: 6.990:  91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 584/641 [1:16:02<07:30,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9988e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.246, mtv: 7.122, ptv: 6.125, pmtv: 6.902:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌      | 609/641 [1:19:21<04:13,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9988e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.280, mtv: 7.288, ptv: 6.127, pmtv: 7.077:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 634/641 [1:22:39<00:55,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9987e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.244, mtv: 7.230, ptv: 6.107, pmtv: 7.028: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 641/641 [1:23:35<00:00,  7.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 1, average traning loss is 3.546174607671181.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 3.249, mtv: 6.629, ptv: 6.050, pmtv: 6.706:   0%|▏                                                                                                                                 | 1/641 [00:07<1:24:30,  7.92s/it]"
     ]
    }
   ],
   "source": [
    "step_count = 0\n",
    "optim.zero_grad()\n",
    "pert_task = 0\n",
    "for e in range(10):\n",
    "    model.train()\n",
    "    losses = {(0, 0): [], (0, 1): [], (1, 0): [], (1, 1): []}\n",
    "    for (bcontrol, bpert, bpert_index) in (pbar := tqdm(iter(dl))):\n",
    "        for i in range(batch_size // minibatch_size):\n",
    "            control = bcontrol[(i * minibatch_size):((i + 1) * minibatch_size)]\n",
    "            pert = bpert[(i * minibatch_size):((i + 1) * minibatch_size)]\n",
    "            pert_index = bpert_index[(i * minibatch_size):((i + 1) * minibatch_size)]\n",
    "            active_weights = 10 * (control > 0).float().to(device) + 1\n",
    "            control = control.float().to(device)\n",
    "            pert = pert.float().to(device)\n",
    "            step_count += 1\n",
    "            mask_task = step_count % 2\n",
    "            pert_task = (pert_task + mask_task) % 2\n",
    "            if pert_task:\n",
    "                pert_expr = pert[torch.arange(pert.size(0)), pert_index[:, 0], None]\n",
    "                pert_recon, _, _ = model(control, pert_expr=pert_expr, pert_index=pert_index[:, 0], mask=mask_task)\n",
    "                loss = torch.sum(active_weights * torch.abs(pert_recon - pert)) / minibatch_size\n",
    "            else:\n",
    "                control_recon, _, _ = model(control, mask=mask_task)\n",
    "                loss = torch.sum(active_weights * torch.abs(control_recon - control)) / minibatch_size\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            losses[(pert_task, mask_task)].append(loss.item())\n",
    "            if step_count % 100 == 0:\n",
    "                lr_scheduler.step()\n",
    "            if pert_task == 0 and mask_task == 0:\n",
    "                pbar.set_description(\n",
    "                    f\"tv: {np.array(losses[(0, 0)])[-100:].mean():.3f}, mtv: {np.array(losses[(0, 1)])[-100:].mean():.3f}, ptv: {np.array(losses[(1, 0)])[-100:].mean():.3f}, pmtv: {np.array(losses[(1, 1)])[-100:].mean():.3f}\")\n",
    "    \n",
    "    avg_loss = sum(losses[(0, 0)]) / len(losses[(0, 0)])\n",
    "    torch.save(model, f\"transformer_v4.{e}\")\n",
    "    # writer.add_scalar('mae_loss', avg_loss, global_step=e)\n",
    "    print(f'In epoch {e}, average traning loss is {avg_loss}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                            | 0/641 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 642.00 MiB. GPU 0 has a total capacty of 31.73 GiB of which 554.44 MiB is free. Including non-PyTorch memory, this process has 31.19 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 431.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pert_task:\n\u001b[1;32m     15\u001b[0m     pert_expr \u001b[38;5;241m=\u001b[39m pert[torch\u001b[38;5;241m.\u001b[39marange(pert\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)), pert_index[:, \u001b[38;5;241m0\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m---> 16\u001b[0m     pert_recon, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpert_expr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpert_expr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpert_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpert_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_task\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(active_weights \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(pert_recon \u001b[38;5;241m-\u001b[39m pert)) \u001b[38;5;241m/\u001b[39m batch_size\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/om2/user/njwfish/anaconda/envs/dsbm/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/om2/user/njwfish/anaconda/envs/dsbm/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/orcd/archive/abugoot/001/Projects/njwfish/sandbox/cfm/llm.py:164\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, batch, mask, pert_index, pert_expr)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding \u001b[38;5;241m=\u001b[39m PosEmbedding(input_dim\u001b[38;5;241m=\u001b[39minput_dim)\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m MAE_Encoder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding, encoder_layer, encoder_head, mask_ratio)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpert_embedding \u001b[38;5;241m=\u001b[39m PertEmbedder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m MAE_Decoder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding, decoder_layer, decoder_head)\n",
      "File \u001b[0;32m/om2/user/njwfish/anaconda/envs/dsbm/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/om2/user/njwfish/anaconda/envs/dsbm/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/orcd/archive/abugoot/001/Projects/njwfish/sandbox/cfm/llm.py:129\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, features, backward_indexes, pert_features)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features, backward_indexes, pert_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    128\u001b[0m     T \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 129\u001b[0m     features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    130\u001b[0m         [features, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_token\u001b[38;5;241m.\u001b[39mexpand(features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], backward_indexes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n\u001b[1;32m    132\u001b[0m     features \u001b[38;5;241m=\u001b[39m take_indexes(features, backward_indexes)\n\u001b[1;32m    133\u001b[0m     features \u001b[38;5;241m=\u001b[39m features \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding\u001b[38;5;241m.\u001b[39mpos\n",
      "File \u001b[0;32m/om2/user/njwfish/anaconda/envs/dsbm/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/om2/user/njwfish/anaconda/envs/dsbm/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/om2/user/njwfish/anaconda/envs/dsbm/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/om2/user/njwfish/anaconda/envs/dsbm/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/om2/user/njwfish/anaconda/envs/dsbm/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/om2/user/njwfish/anaconda/envs/dsbm/lib/python3.10/site-packages/torch/nn/modules/transformer.py:708\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[38;5;241m=\u001b[39mis_causal))\n\u001b[0;32m--> 708\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/om2/user/njwfish/anaconda/envs/dsbm/lib/python3.10/site-packages/torch/nn/modules/transformer.py:723\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 723\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[0;32m/om2/user/njwfish/anaconda/envs/dsbm/lib/python3.10/site-packages/torch/nn/functional.py:1471\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 642.00 MiB. GPU 0 has a total capacty of 31.73 GiB of which 554.44 MiB is free. Including non-PyTorch memory, this process has 31.19 GiB memory in use. Of the allocated memory 30.39 GiB is allocated by PyTorch, and 431.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "step_count = 0\n",
    "optim.zero_grad()\n",
    "pert_task = 0\n",
    "for e in range(10):\n",
    "    model.train()\n",
    "    losses = {(0, 0): [], (0, 1): [], (1, 0): [], (1, 1): []}\n",
    "    for (control, pert, pert_index) in (pbar := tqdm(iter(dl))):\n",
    "        active_weights = 1 # 10 * (control > 0).float().to(device) + 1\n",
    "        control = control.float().to(device)\n",
    "        pert = pert.float().to(device)\n",
    "        step_count += 1\n",
    "        mask_task = step_count % 2\n",
    "        pert_task = (pert_task + mask_task) % 2\n",
    "        if pert_task:\n",
    "            pert_expr = pert[torch.arange(pert.size(0)), pert_index[:, 0], None]\n",
    "            pert_recon, _, _ = model(control, pert_expr=pert_expr, pert_index=pert_index[:, 0], mask=mask_task)\n",
    "            loss = torch.sum(active_weights * torch.abs(pert_recon - pert)) / batch_size\n",
    "        else:\n",
    "            control_recon, _, _ = model(control, mask=mask_task)\n",
    "            loss = torch.sum(active_weights * torch.abs(control_recon - control)) / batch_size\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        if step_count % 100 == 0:\n",
    "            lr_scheduler.step()\n",
    "        losses[(pert_task, mask_task)].append(loss.item())\n",
    "        if pert_task == 0 and mask_task == 0:\n",
    "            pbar.set_description(\n",
    "                f\"tv: {np.array(losses[(0, 0)])[-100:].mean():.3f}, mtv: {np.array(losses[(0, 1)])[-100:].mean():.3f}, ptv: {np.array(losses[(1, 0)])[-100:].mean():.3f}, pmtv: {np.array(losses[(1, 1)])[-100:].mean():.3f}\")\n",
    "    \n",
    "    avg_loss = sum(losses[(0, 0)]) / len(losses[(0, 0)])\n",
    "    torch.save(model, f\"transformer_v5.{e}\")\n",
    "    # writer.add_scalar('mae_loss', avg_loss, global_step=e)\n",
    "    print(f'In epoch {e}, average traning loss is {avg_loss}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_names = adata.obs[cell_col]\n",
    "pert_type_names = adata.obs[pert_col]\n",
    "# Save the predicted perturbation\n",
    "for cell_type, pert_type in zip(holdout_cells, holdout_perts):\n",
    "    control_eval = X[cell_type_names == cell_type]\n",
    "    true_pert= X[(pert_type_names == pert_type) & (cell_type_names == cell_type)]\n",
    "    # cheating right now, just trying to get a mvp together\n",
    "    pert_expr = true_pert[torch.arange(true_pert.size(0)), pert_type, None]\n",
    "    pred_pert, _, _ = model(\n",
    "        control, pert_expr=pert_expr, pert_index=pert_type, mask=False\n",
    "    )\n",
    "    print(f\"Saving {pert_type} predictions\")\n",
    "    np.savez(\n",
    "        f\"Satija_IFNB_HVG/llm/pred_{gene_unmap[pert_type]}_{cell_type}.npz\", \n",
    "        pred_pert=pred_pert[:, hvg_idx].cpu().detach().numpy(), \n",
    "        true_pert=true_pert[:, hvg_idx], \n",
    "        control=control_eval[:, hvg_idx],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsbm",
   "language": "python",
   "name": "dsbm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
