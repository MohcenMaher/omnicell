{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "import scvi\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "\n",
    "import scanpy as sc\n",
    "\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from datamodules import  SCFMDataset, cfm_collate, StratifiedBatchSampler, ot_collate\n",
    "from torch.utils.data import RandomSampler\n",
    "from sc_etl_utils import *\n",
    "from arch import *\n",
    "from flow_utils import compute_conditional_flow\n",
    "import json\n",
    "\n",
    "import scvi\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "\n",
    "import scanpy as sc\n",
    "\n",
    "from torchcfm.conditional_flow_matching import *\n",
    "import scanpy as sc\n",
    "import hashlib\n",
    "from llm import MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some data\n",
    "adata = sc.read_h5ad('/orcd/archive/abugoot/001/Projects/dlesman/datasets/satija_IFNB_HVG_and_perturbed_genes_raw.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_map = {k: i for i, k in enumerate(adata.var.index)}\n",
    "gene_map = gene_map | {'NT': max(gene_map.values()) + 1}\n",
    "gene_unmap = {gene_map[k]: k for k in gene_map}\n",
    "perts = adata.obs.gene.unique().map(gene_map)\n",
    "adata.obs['pert_type'] = adata.obs.gene.map(gene_map)\n",
    "pert_ids = np.array(adata.obs['pert_type'])\n",
    "pert_mat = np.arange(pert_ids.max() + 1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_col = 'cell_type'\n",
    "pert_col = 'pert_type'\n",
    "control_pert, holdout_cells, holdout_perts = gene_map['NT'], ['HT29'], [gene_map['USP18']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 14582, Perturbations: 313080,  Eval: 880\n"
     ]
    }
   ],
   "source": [
    "from sc_etl_utils import *\n",
    "control_idx, pert_idx, eval_idx, eval_cell_idx, eval_pert_idx = get_train_eval_idxs(\n",
    "    adata, control_pert, holdout_cells, holdout_perts, cell_col=cell_col, pert_col=pert_col\n",
    ")\n",
    "\n",
    "_, _, cell_types = get_identity_features(\n",
    "    adata, cell_col=cell_col, pert_col=pert_col, cell_type_features=False\n",
    ")\n",
    "\n",
    "adata.obsm[\"standard\"] = adata.X\n",
    "X = adata.obsm[\"standard\"]\n",
    "X = X.toarray()\n",
    "X = X / X.sum(axis=1)[:, None]\n",
    "\n",
    "control_train, pert_train, pert_ids_train, control_cell_types, pert_cell_types, control_eval, pert_eval, pert_ids_eval = get_train_eval(\n",
    "    X, pert_ids, cell_types, control_idx, pert_idx, eval_idx, eval_cell_idx, eval_pert_idx\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strata probs [0.         0.0001086  0.00030344 0.00039606 0.00040565 0.00041523\n",
      " 0.00042162 0.00043439 0.00045356 0.00045995 0.00049189 0.00052063\n",
      " 0.00054938 0.00056535 0.00061007 0.00062284 0.00062604 0.00062604\n",
      " 0.00063562 0.00068673 0.00075061 0.00076977 0.00077297 0.00077935\n",
      " 0.00079852 0.0008081  0.00084323 0.0008624  0.00087837 0.00088156\n",
      " 0.00088795 0.00088795 0.00089753 0.00089753 0.0009167  0.00092628\n",
      " 0.00093906 0.00094864 0.00099016 0.00099016 0.00100294 0.00104127\n",
      " 0.00104446 0.00105085 0.00109237 0.00110834 0.00110834 0.00111154\n",
      " 0.00111473 0.00111473 0.0011307  0.0011339  0.00113709 0.00116584\n",
      " 0.00117222 0.00117222 0.00121375 0.00121694 0.00122333 0.00122652\n",
      " 0.00124569 0.00124888 0.00124888 0.00126485 0.00128082 0.00129999\n",
      " 0.00130318 0.00130318 0.00131596 0.00131596 0.00132554 0.00133193\n",
      " 0.00133512 0.0013447  0.00135109 0.00137026 0.00137984 0.00137984\n",
      " 0.00139262 0.0014022  0.00140539 0.00140539 0.00141178 0.00141497\n",
      " 0.00141817 0.00143733 0.00146288 0.00146608 0.00146927 0.00147566\n",
      " 0.00148205 0.00148844 0.00149483 0.00152357 0.00152677 0.00152677\n",
      " 0.00153635 0.00153954 0.00153954 0.00154274 0.00154274 0.00154912\n",
      " 0.00155232 0.0015619  0.0015651  0.00157468 0.00158426 0.00158745\n",
      " 0.00160023 0.00160662 0.00161301 0.00162578 0.00162578 0.00162898\n",
      " 0.00164175 0.00164495 0.0016705  0.00167689 0.00167689 0.00168328\n",
      " 0.00168647 0.00169605 0.00169925 0.00173119 0.00173438 0.00173758\n",
      " 0.00175993 0.00176632 0.0017791  0.00180465 0.00180784 0.00181104\n",
      " 0.00181423 0.00181743 0.00183979 0.00183979 0.00184937 0.00185576\n",
      " 0.00185895 0.00186214 0.00187492 0.00188131 0.00188131 0.00190047\n",
      " 0.00190686 0.00192283 0.00193561 0.00193561 0.00197074 0.00198032\n",
      " 0.00198352 0.00198671 0.00199629 0.00200907 0.00201227 0.00202504\n",
      " 0.0020474  0.00205698 0.00206656 0.00208253 0.00209212 0.00209851\n",
      " 0.00213045 0.00214322 0.002156   0.00217836 0.00217836 0.00217836\n",
      " 0.00219752 0.0022103  0.0022103  0.00221349 0.00221349 0.00221988\n",
      " 0.00223266 0.00223585 0.00223904 0.00227418 0.00228057 0.00228376\n",
      " 0.00228696 0.00228696 0.00230293 0.00230931 0.00231251 0.00235084\n",
      " 0.00235084 0.00235403 0.00237639 0.00241791 0.00242749 0.00242749\n",
      " 0.00243069 0.00244027 0.00245305 0.00248179 0.00249138 0.00249776\n",
      " 0.00250415 0.00251373 0.00254248 0.00254248 0.00254248 0.00255526\n",
      " 0.00257762 0.0025872  0.00262553 0.0026383  0.0026415  0.00267344\n",
      " 0.00267344 0.00268941 0.0026958  0.00271177 0.00271496 0.00273093\n",
      " 0.00273093 0.00273413 0.00275648 0.00277565 0.00278842 0.00280759\n",
      " 0.00287466 0.00288744 0.00292896 0.00294493 0.00298007 0.0030184\n",
      " 0.00303437 0.00306631 0.0030695  0.00308867 0.00309186 0.00310144\n",
      " 0.00311422 0.00311422 0.00313019 0.00313658 0.00313658 0.00314297\n",
      " 0.00314297 0.00314297 0.00314616 0.0031781  0.0031813  0.00318768\n",
      " 0.00319088 0.00320046 0.00321643 0.00323879 0.00324198 0.00324518\n",
      " 0.0032867  0.00332183 0.00332503 0.00332822 0.00333461 0.00333781\n",
      " 0.00333781 0.0033921  0.00340488 0.00345918 0.00346876 0.0035007\n",
      " 0.00352626 0.00353903 0.00354542 0.00356778 0.00357097 0.00357417\n",
      " 0.00359652 0.00360291 0.00363166 0.00363166 0.00364444 0.00365082\n",
      " 0.00366679 0.00367957 0.00372109 0.00372109 0.00373387 0.00373706\n",
      " 0.00374984 0.00376262 0.0037722  0.00379456 0.00381692 0.00384247\n",
      " 0.00384247 0.00389038 0.00392871 0.0039319  0.00394148 0.00394787\n",
      " 0.00397023 0.00402453 0.00402772 0.00403411 0.00407883 0.00408202\n",
      " 0.00409161 0.00409161 0.00411077 0.00411716 0.00414271 0.00420659\n",
      " 0.00421617 0.00421937 0.00423534 0.00424173 0.0042545  0.00428964\n",
      " 0.00431519 0.00432477 0.00436949 0.00437268 0.00438227 0.00439504\n",
      " 0.00442379 0.00445254 0.00459627 0.00462182 0.00469848 0.00470167\n",
      " 0.00470806 0.00473042 0.0047432  0.00485499 0.00487415 0.00489971\n",
      " 0.00506899 0.00510413 0.00512329 0.00512329 0.00523828 0.00535326\n",
      " 0.00539479 0.00540437 0.00542353 0.00543631 0.00545867 0.00553533\n",
      " 0.00553852 0.0055513  0.00558004 0.00570461 0.00572697 0.00575891\n",
      " 0.00579405 0.00590584 0.00609109 0.006468   0.00648716 0.00654465\n",
      " 0.00657021 0.00693752 0.00694391 0.00706529 0.00720263 0.00798199\n",
      " 0.00804267 0.00858247 0.00904561 0.009266   0.00959499 0.01232912]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "dset = SCFMDataset(\n",
    "    control_train, pert_train, \n",
    "    pert_ids_train, pert_mat, \n",
    "    control_cell_types, pert_cell_types,\n",
    "    batch_size=batch_size, size=X.shape[0]\n",
    ")\n",
    "ns = np.array([[t.shape[0] for t in ts] for ts in dset.target])\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    dset, collate_fn=ot_collate, \n",
    "    batch_sampler=StratifiedBatchSampler(\n",
    "        ns=ns, batch_size=512\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MAE(\n",
    "    X.shape[1], emb_dim=24, decoder_layer=4, encoder_layer=4, encoder_head=3, decoder_head=3, ff_dim=128,\n",
    "    true_sparsity=False, expr_activation=\"sigmoid\"\n",
    ")\n",
    "# model = torch.load(f\"...\")\n",
    "device = 'cuda'\n",
    "# device = 'cpu'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 5e-4\n",
    "weight_decay=0.0\n",
    "total_epoch = 500\n",
    "warmup_epoch = 1\n",
    "minibatch_size = 128\n",
    "save_dir = \"llm/v\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are two training loops, first is just the autoencoder and second is the autoencoder and pert task. I usually run the autoencoder for a couple iterations then the joint task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    }
   ],
   "source": [
    "base_learning_rate = 5e-5\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=base_learning_rate, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
    "lr_func = lambda epoch: min((epoch + 1) / (warmup_epoch + 1e-5), 0.5 * (math.cos(epoch / total_epoch * math.pi) + 1))\n",
    "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=lr_func, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 2123.005:   0%|                                                                                                                                                                              | 0/611 [00:03<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "use_sparsity_loss = False\n",
    "use_mask_task = False\n",
    "use_active_weights = True\n",
    "lr_step = 32\n",
    "\n",
    "step_count = 0\n",
    "optim.zero_grad()\n",
    "pert_task = 0\n",
    "for e in range(2):\n",
    "    model.train()\n",
    "    losses = {'control': [], 'pert': []}\n",
    "    for (bcontrol, bpert, bpert_index) in (pbar := tqdm(iter(dl))):\n",
    "        curr_batch_size = bcontrol.shape[0]\n",
    "        for i in range(curr_batch_size // minibatch_size):\n",
    "            control = bcontrol[(i * minibatch_size):((i + 1) * minibatch_size)]\n",
    "            pert = bpert[(i * minibatch_size):((i + 1) * minibatch_size)]\n",
    "            pert_index = bpert_index[(i * minibatch_size):((i + 1) * minibatch_size)]\n",
    "            pert_index = pert_index.squeeze()\n",
    "            active_weights = 10 * (control > 0).float().to(device) + 1 if use_active_weights else 1\n",
    "            control = control.float().to(device)\n",
    "            step_count += 1\n",
    "\n",
    "            control_results = model(control, mask=use_mask_task)\n",
    "            control_recon = control_results[0]\n",
    "            \n",
    "            control_loss = torch.sum(active_weights * torch.abs(control_recon - control)) / minibatch_size\n",
    "            if use_sparsity_loss and len(control_results) == 3:\n",
    "                control_sparsity = control_results[1]\n",
    "                control_loss += torch.sum(active_weights * torch.abs(control_sparsity - (control > 0).float())) / minibatch_size\n",
    "\n",
    "            loss = control_loss\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            losses['control'].append(control_loss.item())\n",
    "            if step_count % lr_step == 0:\n",
    "                lr_scheduler.step()\n",
    "\n",
    "            pbar.set_description(\n",
    "                f\"tv: {np.array(losses['control'])[-lr_step:].mean():.3f}\"\n",
    "            )\n",
    "    \n",
    "    avg_loss = sum(losses['control']) / len(losses['control'])\n",
    "    torch.save(model, f\"{save_dir}{e}\")\n",
    "    # writer.add_scalar('mae_loss', avg_loss, global_step=e)\n",
    "    print(f'In epoch {e}, average traning loss is {avg_loss}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1986.251, ptv: 2031.380:   1%|█▉                                                                                                                                                   | 8/611 [01:14<1:32:10,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1774.949, ptv: 1799.242:   3%|███▉                                                                                                                                                | 16/611 [02:29<1:32:45,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1655.834, ptv: 1673.001:   4%|██████                                                                                                                                              | 25/611 [03:45<1:31:38,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1296.967, ptv: 1319.913:   5%|███████▉                                                                                                                                            | 33/611 [05:01<1:23:12,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 1112.240, ptv: 1138.553:   7%|█████████▉                                                                                                                                          | 41/611 [06:17<1:29:47,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 944.278, ptv: 962.950:   8%|████████████▎                                                                                                                                         | 50/611 [07:33<1:23:31,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 823.816, ptv: 844.687:   9%|██████████████▏                                                                                                                                       | 58/611 [08:49<1:20:52,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 719.038, ptv: 726.769:  11%|████████████████▏                                                                                                                                     | 66/611 [10:05<1:24:25,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 626.998, ptv: 631.751:  12%|██████████████████▍                                                                                                                                   | 75/611 [11:21<1:23:43,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 590.837, ptv: 604.652:  14%|████████████████████▍                                                                                                                                 | 83/611 [12:37<1:23:21,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 546.040, ptv: 554.647:  15%|██████████████████████▎                                                                                                                               | 91/611 [13:52<1:22:05,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 532.089, ptv: 542.118:  16%|████████████████████████▎                                                                                                                             | 99/611 [15:08<1:19:48,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 501.481, ptv: 511.651:  18%|██████████████████████████                                                                                                                           | 107/611 [16:24<1:14:43,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 508.120, ptv: 515.469:  19%|████████████████████████████▎                                                                                                                        | 116/611 [17:40<1:14:28,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 519.402, ptv: 521.996:  20%|██████████████████████████████▏                                                                                                                      | 124/611 [18:56<1:16:44,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 474.387, ptv: 482.025:  22%|████████████████████████████████▏                                                                                                                    | 132/611 [20:12<1:15:42,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9999e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tv: 478.445, ptv: 487.510:  22%|█████████████████████████████████▏                                                                                                                   | 136/611 [20:57<1:13:11,  9.24s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# pert_loss += torch.sum(pert_active_weights * torch.abs(pert_sparsity - (pert > 0).float())) / minibatch_size\u001b[39;00m\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m (pert_loss \u001b[38;5;241m+\u001b[39m control_loss)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     34\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/om2/user/njwfish/anaconda/envs/dsbm/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/om2/user/njwfish/anaconda/envs/dsbm/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "use_sparsity_loss = False\n",
    "use_mask_task = False\n",
    "use_active_weights = True\n",
    "lr_step = 32\n",
    "\n",
    "step_count = 0\n",
    "optim.zero_grad()\n",
    "pert_task = 0\n",
    "for e in range(2):\n",
    "    model.train()\n",
    "    losses = {'control': [], 'pert': []}\n",
    "    for (bcontrol, bpert, bpert_index) in (pbar := tqdm(iter(dl))):\n",
    "        curr_batch_size = bcontrol.shape[0]\n",
    "        for i in range(curr_batch_size // minibatch_size):\n",
    "            control = bcontrol[(i * minibatch_size):((i + 1) * minibatch_size)]\n",
    "            pert = bpert[(i * minibatch_size):((i + 1) * minibatch_size)]\n",
    "            pert_index = bpert_index[(i * minibatch_size):((i + 1) * minibatch_size)]\n",
    "            pert_index = pert_index.squeeze()\n",
    "            active_weights = 10 * (control > 0).float().to(device) + 1 if use_active_weights else 1\n",
    "            pert_active_weights = 10 * (pert > 0).float().to(device) + 1 if use_active_weights else 1\n",
    "            control = control.float().to(device)\n",
    "            pert = pert.float().to(device)\n",
    "            step_count += 1\n",
    "\n",
    "            pert_expr = pert[torch.arange(pert.size(0)), pert_index, None]\n",
    "            control_results, pert_results = model(\n",
    "                control, pert_expr=pert_expr, pert_index=pert_index, mask=use_mask_task, recon_and_pert=True\n",
    "            )\n",
    "            \n",
    "            control_recon, pert_recon = control_results[0], pert_results[0]\n",
    "            control_loss = torch.sum(active_weights * torch.abs(control_recon - control)) / minibatch_size\n",
    "            pert_loss = torch.sum(pert_active_weights * torch.abs(pert_recon - pert)) / minibatch_size\n",
    "            \n",
    "            if use_sparsity_loss and len(control_results) == 3:\n",
    "                control_sparsity, pert_sparsity = control_results[1], pert_results[1]\n",
    "                control_loss += torch.sum(active_weights * torch.abs(control_sparsity - (control > 0).float())) / minibatch_size\n",
    "                pert_loss += torch.sum(pert_active_weights * torch.abs(pert_sparsity - (pert > 0).float())) / minibatch_size\n",
    "\n",
    "            loss = (pert_loss + control_loss)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            losses['control'].append(control_loss.item())\n",
    "            losses['pert'].append(pert_loss.item())\n",
    "            if step_count % lr_step == 0:\n",
    "                lr_scheduler.step()\n",
    "            pbar.set_description(\n",
    "                f\"tv: {np.array(losses['control'])[-lr_step:].mean():.3f}, ptv: {np.array(losses['pert'])[-lr_step:].mean():.3f}\"\n",
    "            )\n",
    "    \n",
    "    avg_loss = sum(losses['control']) / len(losses['control'])\n",
    "    torch.save(model, f\"{save_dir}{e}\")\n",
    "    # writer.add_scalar('mae_loss', avg_loss, global_step=e)\n",
    "    print(f'In epoch {e}, average traning loss is {avg_loss}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "Saving USP18 predictions\n"
     ]
    }
   ],
   "source": [
    "cell_type_names = adata.obs[cell_col]\n",
    "pert_type_names = adata.obs[pert_col]\n",
    "# Save the predicted perturbation\n",
    "for cell_type, pert_type in zip(holdout_cells, holdout_perts):\n",
    "    control_eval =  torch.tensor(X[cell_type_names == cell_type]).float()# .to(device)\n",
    "    true_pert= torch.tensor(X[(pert_type_names == pert_type) & (cell_type_names == cell_type)]).float()# .to(device)\n",
    "    curr_batch_size = min(control_eval.shape[0], true_pert.shape[0])\n",
    "    pred_perts = []\n",
    "    for i in range(curr_batch_size // minibatch_size + 1):\n",
    "        print(i)\n",
    "        control = control_eval[(i * minibatch_size):min(curr_batch_size, ((i + 1) * minibatch_size))].to(device)\n",
    "        pert = true_pert[(i * minibatch_size):min(curr_batch_size, ((i + 1) * minibatch_size))].to(device)\n",
    "        pert_expr = pert[torch.arange(pert.shape[0]), pert_type, None]\n",
    "        pred_pert, _, _, = model(\n",
    "            control, pert_expr=pert_expr, pert_index=pert_type, mask=False\n",
    "        )\n",
    "        control.cpu().numpy()\n",
    "        pert.cpu().numpy()\n",
    "        pred_perts.append(pred_pert.cpu().detach().numpy())\n",
    "        torch.cuda.empty_cache()\n",
    "    pred_pert = np.vstack(pred_perts)\n",
    "    print(f\"Saving {gene_unmap[pert_type]} predictions\")\n",
    "    np.savez(\n",
    "        f\"Satija_IFNB_HVG/llm/pred_{gene_unmap[pert_type]}_{cell_type}.npz\", \n",
    "        pred_pert=pred_pert, \n",
    "        true_pert=true_pert, \n",
    "        control=control_eval,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsbm",
   "language": "python",
   "name": "dsbm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
